{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b565c22f",
   "metadata": {},
   "source": [
    "# With OnehotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83f7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "data = pd.read_excel('E:/Sales (2).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc86d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Billing Date</th>\n",
       "      <th>Customer</th>\n",
       "      <th>Material Number</th>\n",
       "      <th>Material Group</th>\n",
       "      <th>Qty</th>\n",
       "      <th>UoM</th>\n",
       "      <th>Net Value in Doc Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>10000519</td>\n",
       "      <td>300216</td>\n",
       "      <td>10000001</td>\n",
       "      <td>960.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>67200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>10002347</td>\n",
       "      <td>300204</td>\n",
       "      <td>10000001</td>\n",
       "      <td>82.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>3717.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>10002347</td>\n",
       "      <td>300236</td>\n",
       "      <td>10000001</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>146720.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>10002347</td>\n",
       "      <td>300236</td>\n",
       "      <td>10000001</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>183400.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>10002347</td>\n",
       "      <td>300236</td>\n",
       "      <td>10000001</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>KG</td>\n",
       "      <td>201740.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Billing Date  Customer  Material Number  Material Group     Qty UoM  \\\n",
       "0   2019-04-01  10000519           300216        10000001   960.0  KG   \n",
       "1   2019-04-01  10002347           300204        10000001    82.0  KG   \n",
       "2   2019-04-01  10002347           300236        10000001  4000.0  KG   \n",
       "3   2019-04-01  10002347           300236        10000001  5000.0  KG   \n",
       "4   2019-04-01  10002347           300236        10000001  5500.0  KG   \n",
       "\n",
       "   Net Value in Doc Currency  \n",
       "0                   67200.00  \n",
       "1                    3717.06  \n",
       "2                  146720.00  \n",
       "3                  183400.00  \n",
       "4                  201740.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09169183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 152683 entries, 0 to 152682\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   Billing Date               152683 non-null  datetime64[ns]\n",
      " 1   Customer                   152683 non-null  int64         \n",
      " 2   Material Number            152683 non-null  int64         \n",
      " 3   Material Group             152683 non-null  int64         \n",
      " 4   Qty                        152683 non-null  float64       \n",
      " 5   UoM                        152683 non-null  object        \n",
      " 6   Net Value in Doc Currency  152683 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(3), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7723362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Customer' , 'Material Number' , 'Qty' , 'UoM'] , axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff44c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['Date' , 'Material' , 'Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be17123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Material</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>10000001</td>\n",
       "      <td>602777.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>10000002</td>\n",
       "      <td>178063.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>10000003</td>\n",
       "      <td>216684.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>10000005</td>\n",
       "      <td>5151641.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>10000007</td>\n",
       "      <td>2580483.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Material       Sales\n",
       "0  2019-04-01  10000001   602777.06\n",
       "1  2019-04-01  10000002   178063.20\n",
       "2  2019-04-01  10000003   216684.00\n",
       "3  2019-04-01  10000005  5151641.82\n",
       "4  2019-04-01  10000007  2580483.11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Date'] = data['Date'].apply(lambda x: str(x)[:-9])  \n",
    "data = data.groupby(['Date' , 'Material'])['Sales'].sum().reset_index()\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c9235a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000001    91\n",
       "10000019    91\n",
       "10000007    91\n",
       "10000009    91\n",
       "10000011    91\n",
       "10000013    91\n",
       "10000015    91\n",
       "10000017    91\n",
       "10000021    91\n",
       "10000040    91\n",
       "10000023    91\n",
       "10000029    91\n",
       "10000031    91\n",
       "10000033    91\n",
       "10000035    91\n",
       "10000037    91\n",
       "10000005    91\n",
       "10000039    91\n",
       "10000020    91\n",
       "10000008    91\n",
       "10000010    91\n",
       "10000034    91\n",
       "10000012    91\n",
       "10000030    91\n",
       "10000028    91\n",
       "10000014    91\n",
       "10000024    91\n",
       "10000022    91\n",
       "10000036    91\n",
       "10000018    91\n",
       "10000016    91\n",
       "10000027    89\n",
       "10000025    89\n",
       "10000002    70\n",
       "10000003    63\n",
       "10000004    62\n",
       "10000026    56\n",
       "10000006     7\n",
       "10000032     6\n",
       "10000038     2\n",
       "Name: Material, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Material'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70fcfd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000001 10000002 10000003 10000005 10000007 10000008 10000009 10000010\n",
      " 10000011 10000012 10000013 10000014 10000015 10000016 10000017 10000018\n",
      " 10000019 10000020 10000021 10000022 10000023 10000024 10000025 10000027\n",
      " 10000028 10000029 10000030 10000031 10000033 10000034 10000035 10000036\n",
      " 10000037 10000039 10000040 10000026 10000004 10000038 10000032 10000006]\n"
     ]
    }
   ],
   "source": [
    "lister = data['Material'].unique()\n",
    "print(lister)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6194e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in lister:\n",
    "    data.insert(1 , str(i) , np.zeros(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52153f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>10000006</th>\n",
       "      <th>10000032</th>\n",
       "      <th>10000038</th>\n",
       "      <th>10000004</th>\n",
       "      <th>10000026</th>\n",
       "      <th>10000040</th>\n",
       "      <th>10000039</th>\n",
       "      <th>10000037</th>\n",
       "      <th>10000036</th>\n",
       "      <th>...</th>\n",
       "      <th>10000010</th>\n",
       "      <th>10000009</th>\n",
       "      <th>10000008</th>\n",
       "      <th>10000007</th>\n",
       "      <th>10000005</th>\n",
       "      <th>10000003</th>\n",
       "      <th>10000002</th>\n",
       "      <th>10000001</th>\n",
       "      <th>Material</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000001</td>\n",
       "      <td>602777.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000002</td>\n",
       "      <td>178063.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000003</td>\n",
       "      <td>216684.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000005</td>\n",
       "      <td>5151641.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000007</td>\n",
       "      <td>2580483.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  10000006  10000032  10000038  10000004  10000026  10000040  \\\n",
       "0  2019-04-01       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1  2019-04-01       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2  2019-04-01       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3  2019-04-01       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4  2019-04-01       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   10000039  10000037  10000036  ...  10000010  10000009  10000008  10000007  \\\n",
       "0       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "1       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "2       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "3       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "4       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   10000005  10000003  10000002  10000001  Material       Sales  \n",
       "0       0.0       0.0       0.0       0.0  10000001   602777.06  \n",
       "1       0.0       0.0       0.0       0.0  10000002   178063.20  \n",
       "2       0.0       0.0       0.0       0.0  10000003   216684.00  \n",
       "3       0.0       0.0       0.0       0.0  10000005  5151641.82  \n",
       "4       0.0       0.0       0.0       0.0  10000007  2580483.11  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17085646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000001\n",
      "602777.06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>10000006</th>\n",
       "      <th>10000032</th>\n",
       "      <th>10000038</th>\n",
       "      <th>10000004</th>\n",
       "      <th>10000026</th>\n",
       "      <th>10000040</th>\n",
       "      <th>10000039</th>\n",
       "      <th>10000037</th>\n",
       "      <th>10000036</th>\n",
       "      <th>...</th>\n",
       "      <th>10000010</th>\n",
       "      <th>10000009</th>\n",
       "      <th>10000008</th>\n",
       "      <th>10000007</th>\n",
       "      <th>10000005</th>\n",
       "      <th>10000003</th>\n",
       "      <th>10000002</th>\n",
       "      <th>10000001</th>\n",
       "      <th>Material</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>602777.06</td>\n",
       "      <td>10000001</td>\n",
       "      <td>602777.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178063.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10000002</td>\n",
       "      <td>178063.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>216684.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10000003</td>\n",
       "      <td>216684.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5151641.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10000005</td>\n",
       "      <td>5151641.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2580483.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10000007</td>\n",
       "      <td>2580483.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  10000006  10000032  10000038  10000004  10000026  10000040  \\\n",
       "0  2019-04-01       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1  2019-04-01       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2  2019-04-01       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3  2019-04-01       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4  2019-04-01       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   10000039  10000037  10000036  ...  10000010  10000009  10000008  \\\n",
       "0       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "1       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "2       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "3       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "4       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "\n",
       "     10000007    10000005  10000003  10000002   10000001  Material       Sales  \n",
       "0        0.00        0.00       0.0       0.0  602777.06  10000001   602777.06  \n",
       "1        0.00        0.00       0.0  178063.2       0.00  10000002   178063.20  \n",
       "2        0.00        0.00  216684.0       0.0       0.00  10000003   216684.00  \n",
       "3        0.00  5151641.82       0.0       0.0       0.00  10000005  5151641.82  \n",
       "4  2580483.11        0.00       0.0       0.0       0.00  10000007  2580483.11  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(data.loc[0 , 'Material']))\n",
    "print(data.loc[0 , 'Sales'])\n",
    "\n",
    "for i in range(len(data)):\n",
    "    x = str(data.loc[i , 'Material'])\n",
    "    data.loc[i , x] = data.loc[i , 'Sales']\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d14f9d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10000001', '10000002', '10000003', '10000005', '10000007', '10000008', '10000009', '10000010', '10000011', '10000012', '10000013', '10000014', '10000015', '10000016', '10000017', '10000018', '10000019', '10000020', '10000021', '10000022', '10000023', '10000024', '10000025', '10000027', '10000028', '10000029', '10000030', '10000031', '10000033', '10000034', '10000035', '10000036', '10000037', '10000039', '10000040', '10000026', '10000004', '10000038', '10000032', '10000006', 'Sales']\n"
     ]
    }
   ],
   "source": [
    "lister = list(map(str, lister))\n",
    "lister.append('Sales')\n",
    "print(lister)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "966e590d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>10000001</th>\n",
       "      <th>10000002</th>\n",
       "      <th>10000003</th>\n",
       "      <th>10000005</th>\n",
       "      <th>10000007</th>\n",
       "      <th>10000008</th>\n",
       "      <th>10000009</th>\n",
       "      <th>10000010</th>\n",
       "      <th>10000011</th>\n",
       "      <th>...</th>\n",
       "      <th>10000036</th>\n",
       "      <th>10000037</th>\n",
       "      <th>10000039</th>\n",
       "      <th>10000040</th>\n",
       "      <th>10000026</th>\n",
       "      <th>10000004</th>\n",
       "      <th>10000038</th>\n",
       "      <th>10000032</th>\n",
       "      <th>10000006</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>602777.06</td>\n",
       "      <td>178063.2</td>\n",
       "      <td>216684.0</td>\n",
       "      <td>5151641.82</td>\n",
       "      <td>2580483.11</td>\n",
       "      <td>2313731.83</td>\n",
       "      <td>726852.28</td>\n",
       "      <td>170344.82</td>\n",
       "      <td>77752.85</td>\n",
       "      <td>...</td>\n",
       "      <td>1036169.01</td>\n",
       "      <td>3025013.80</td>\n",
       "      <td>355094.46</td>\n",
       "      <td>233812.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50648642.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>274240.00</td>\n",
       "      <td>2291000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4483264.36</td>\n",
       "      <td>2084867.32</td>\n",
       "      <td>2318207.75</td>\n",
       "      <td>696174.58</td>\n",
       "      <td>180734.52</td>\n",
       "      <td>369328.01</td>\n",
       "      <td>...</td>\n",
       "      <td>996406.24</td>\n",
       "      <td>3078471.84</td>\n",
       "      <td>328726.67</td>\n",
       "      <td>358724.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49429212.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>1553522.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107945.0</td>\n",
       "      <td>5750702.46</td>\n",
       "      <td>2585973.88</td>\n",
       "      <td>2909510.91</td>\n",
       "      <td>876963.24</td>\n",
       "      <td>438047.24</td>\n",
       "      <td>123922.59</td>\n",
       "      <td>...</td>\n",
       "      <td>1423093.67</td>\n",
       "      <td>3607853.01</td>\n",
       "      <td>343502.11</td>\n",
       "      <td>286247.69</td>\n",
       "      <td>49419.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58869847.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>3843352.00</td>\n",
       "      <td>25437.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5840138.40</td>\n",
       "      <td>2979784.80</td>\n",
       "      <td>2733588.27</td>\n",
       "      <td>770636.24</td>\n",
       "      <td>251737.51</td>\n",
       "      <td>68695.09</td>\n",
       "      <td>...</td>\n",
       "      <td>1025335.74</td>\n",
       "      <td>3646552.61</td>\n",
       "      <td>669379.13</td>\n",
       "      <td>217040.86</td>\n",
       "      <td>138109.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60938957.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>4205908.00</td>\n",
       "      <td>1657290.0</td>\n",
       "      <td>212734.2</td>\n",
       "      <td>5600504.71</td>\n",
       "      <td>2366882.52</td>\n",
       "      <td>2602766.12</td>\n",
       "      <td>709088.41</td>\n",
       "      <td>630929.56</td>\n",
       "      <td>50410.65</td>\n",
       "      <td>...</td>\n",
       "      <td>1060735.39</td>\n",
       "      <td>3405518.35</td>\n",
       "      <td>284880.90</td>\n",
       "      <td>390380.06</td>\n",
       "      <td>149912.5</td>\n",
       "      <td>811534.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60422859.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    10000001   10000002  10000003    10000005    10000007  \\\n",
       "0  2019-04-01   602777.06   178063.2  216684.0  5151641.82  2580483.11   \n",
       "1  2019-04-02   274240.00  2291000.0       0.0  4483264.36  2084867.32   \n",
       "2  2019-04-03  1553522.60        0.0  107945.0  5750702.46  2585973.88   \n",
       "3  2019-04-04  3843352.00    25437.6       0.0  5840138.40  2979784.80   \n",
       "4  2019-04-05  4205908.00  1657290.0  212734.2  5600504.71  2366882.52   \n",
       "\n",
       "     10000008   10000009   10000010   10000011  ...    10000036    10000037  \\\n",
       "0  2313731.83  726852.28  170344.82   77752.85  ...  1036169.01  3025013.80   \n",
       "1  2318207.75  696174.58  180734.52  369328.01  ...   996406.24  3078471.84   \n",
       "2  2909510.91  876963.24  438047.24  123922.59  ...  1423093.67  3607853.01   \n",
       "3  2733588.27  770636.24  251737.51   68695.09  ...  1025335.74  3646552.61   \n",
       "4  2602766.12  709088.41  630929.56   50410.65  ...  1060735.39  3405518.35   \n",
       "\n",
       "    10000039   10000040  10000026   10000004  10000038  10000032  10000006  \\\n",
       "0  355094.46  233812.11       0.0       0.00       0.0       0.0       0.0   \n",
       "1  328726.67  358724.23       0.0       0.00       0.0       0.0       0.0   \n",
       "2  343502.11  286247.69   49419.6       0.00       0.0       0.0       0.0   \n",
       "3  669379.13  217040.86  138109.8       0.00       0.0       0.0       0.0   \n",
       "4  284880.90  390380.06  149912.5  811534.88       0.0       0.0       0.0   \n",
       "\n",
       "         Sales  \n",
       "0  50648642.57  \n",
       "1  49429212.10  \n",
       "2  58869847.96  \n",
       "3  60938957.87  \n",
       "4  60422859.61  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = data.groupby(['Date'])[lister].sum().reset_index()\n",
    "dm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c680ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 1 # predict 1 step at a time\n",
    "WINDOW_SIZE = 7 # use a week worth of timesteps to predict the horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5962f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10000001', '10000002', '10000003', '10000005', '10000007', '10000008', '10000009', '10000010', '10000011', '10000012', '10000013', '10000014', '10000015', '10000016', '10000017', '10000018', '10000019', '10000020', '10000021', '10000022', '10000023', '10000024', '10000025', '10000027', '10000028', '10000029', '10000030', '10000031', '10000033', '10000034', '10000035', '10000036', '10000037', '10000039', '10000040', '10000026', '10000004', '10000038', '10000032', '10000006']\n"
     ]
    }
   ],
   "source": [
    "lister.remove('Sales')\n",
    "print(lister)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f81e4861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windowed_indexes(x , window_size , horizon):\n",
    "    # 1. Create a window of specific window_size (add the horizon on the end for later labelling)\n",
    "    window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
    "    # print(f\"Window step:\\n {window_step}\")\n",
    "\n",
    "    # 2. Create a 2D array of multiple window steps (minus 1 to account for 0 indexing)\n",
    "    window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T\n",
    "    \n",
    "    return window_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfd8ab92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 8)\n"
     ]
    }
   ],
   "source": [
    "indexes = get_windowed_indexes(dm , WINDOW_SIZE , HORIZON)\n",
    "print(indexes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5279edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10000001.0, 602777.06, 274240.0, 1553522.6, 3843352.0, 4205908.0, 6881344.0, 6101444.0, 1329717.0], [10000002.0, 178063.2, 2291000.0, 0.0, 25437.6, 1657290.0, 1840.0, 1800.0, 17000.0], [10000003.0, 216684.0, 0.0, 107945.0, 0.0, 212734.2, 0.0, 136696.8, 57740.25]]\n"
     ]
    }
   ],
   "source": [
    "full_windows = []\n",
    "# full_labels = []\n",
    "for i in indexes:\n",
    "    for j in range(len(lister)):\n",
    "        win = dm[lister[j]][i]\n",
    "#         win , label = win[:-1] , win[-1:]\n",
    "        win = win.to_numpy()\n",
    "        window = np.insert(win , 0 , lister[j])\n",
    "        full_windows.append(window.tolist())\n",
    "#         full_labels.append(label.to_list())\n",
    "print(full_windows[:3])\n",
    "# print(full_labels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d56176ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# max_windows_val = tf.math.reduce_max(full_windows)\n",
    "# min_windows_val = tf.math.reduce_min(full_windows)\n",
    "# range_windows = max_windows_val - min_windows_val\n",
    "\n",
    "# max_labels_val = tf.math.reduce_max(full_labels)\n",
    "# min_labels_val = tf.math.reduce_min(full_labels)\n",
    "# range_labels = max_labels_val - min_labels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebe7cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_windows = full_windows / range_windows\n",
    "# full_labels = full_labels / range_labels\n",
    "# print(full_windows[:3])\n",
    "# print(full_labels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ce7e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Material</th>\n",
       "      <th>Day-1</th>\n",
       "      <th>Day-2</th>\n",
       "      <th>Day-3</th>\n",
       "      <th>Day-4</th>\n",
       "      <th>Day-5</th>\n",
       "      <th>Day-6</th>\n",
       "      <th>Day-7</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000001.0</td>\n",
       "      <td>602777.06</td>\n",
       "      <td>274240.00</td>\n",
       "      <td>1553522.60</td>\n",
       "      <td>3843352.0</td>\n",
       "      <td>4205908.00</td>\n",
       "      <td>6881344.00</td>\n",
       "      <td>6101444.00</td>\n",
       "      <td>1329717.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000002.0</td>\n",
       "      <td>178063.20</td>\n",
       "      <td>2291000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25437.6</td>\n",
       "      <td>1657290.00</td>\n",
       "      <td>1840.00</td>\n",
       "      <td>1800.00</td>\n",
       "      <td>17000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000003.0</td>\n",
       "      <td>216684.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>107945.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212734.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>136696.80</td>\n",
       "      <td>57740.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000005.0</td>\n",
       "      <td>5151641.82</td>\n",
       "      <td>4483264.36</td>\n",
       "      <td>5750702.46</td>\n",
       "      <td>5840138.4</td>\n",
       "      <td>5600504.71</td>\n",
       "      <td>5056658.57</td>\n",
       "      <td>4572115.32</td>\n",
       "      <td>4654375.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000007.0</td>\n",
       "      <td>2580483.11</td>\n",
       "      <td>2084867.32</td>\n",
       "      <td>2585973.88</td>\n",
       "      <td>2979784.8</td>\n",
       "      <td>2366882.52</td>\n",
       "      <td>2361125.47</td>\n",
       "      <td>2236869.93</td>\n",
       "      <td>2330754.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Material       Day-1       Day-2       Day-3      Day-4       Day-5  \\\n",
       "0  10000001.0   602777.06   274240.00  1553522.60  3843352.0  4205908.00   \n",
       "1  10000002.0   178063.20  2291000.00        0.00    25437.6  1657290.00   \n",
       "2  10000003.0   216684.00        0.00   107945.00        0.0   212734.20   \n",
       "3  10000005.0  5151641.82  4483264.36  5750702.46  5840138.4  5600504.71   \n",
       "4  10000007.0  2580483.11  2084867.32  2585973.88  2979784.8  2366882.52   \n",
       "\n",
       "        Day-6       Day-7  Prediction  \n",
       "0  6881344.00  6101444.00  1329717.00  \n",
       "1     1840.00     1800.00    17000.00  \n",
       "2        0.00   136696.80    57740.25  \n",
       "3  5056658.57  4572115.32  4654375.08  \n",
       "4  2361125.47  2236869.93  2330754.56  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(full_windows , columns = ['Material' , 'Day-1' , 'Day-2' , 'Day-3' , 'Day-4' , 'Day-5' , 'Day-6' , 'Day-7' , 'Prediction'])\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bae5f6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day-1</th>\n",
       "      <th>Day-2</th>\n",
       "      <th>Day-3</th>\n",
       "      <th>Day-4</th>\n",
       "      <th>Day-5</th>\n",
       "      <th>Day-6</th>\n",
       "      <th>Day-7</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Material_10000001.0</th>\n",
       "      <th>Material_10000002.0</th>\n",
       "      <th>...</th>\n",
       "      <th>Material_10000031.0</th>\n",
       "      <th>Material_10000032.0</th>\n",
       "      <th>Material_10000033.0</th>\n",
       "      <th>Material_10000034.0</th>\n",
       "      <th>Material_10000035.0</th>\n",
       "      <th>Material_10000036.0</th>\n",
       "      <th>Material_10000037.0</th>\n",
       "      <th>Material_10000038.0</th>\n",
       "      <th>Material_10000039.0</th>\n",
       "      <th>Material_10000040.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602777.06</td>\n",
       "      <td>274240.00</td>\n",
       "      <td>1553522.60</td>\n",
       "      <td>3843352.0</td>\n",
       "      <td>4205908.00</td>\n",
       "      <td>6881344.00</td>\n",
       "      <td>6101444.00</td>\n",
       "      <td>1329717.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>178063.20</td>\n",
       "      <td>2291000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25437.6</td>\n",
       "      <td>1657290.00</td>\n",
       "      <td>1840.00</td>\n",
       "      <td>1800.00</td>\n",
       "      <td>17000.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>216684.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>107945.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>212734.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>136696.80</td>\n",
       "      <td>57740.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5151641.82</td>\n",
       "      <td>4483264.36</td>\n",
       "      <td>5750702.46</td>\n",
       "      <td>5840138.4</td>\n",
       "      <td>5600504.71</td>\n",
       "      <td>5056658.57</td>\n",
       "      <td>4572115.32</td>\n",
       "      <td>4654375.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2580483.11</td>\n",
       "      <td>2084867.32</td>\n",
       "      <td>2585973.88</td>\n",
       "      <td>2979784.8</td>\n",
       "      <td>2366882.52</td>\n",
       "      <td>2361125.47</td>\n",
       "      <td>2236869.93</td>\n",
       "      <td>2330754.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Day-1       Day-2       Day-3      Day-4       Day-5       Day-6  \\\n",
       "0   602777.06   274240.00  1553522.60  3843352.0  4205908.00  6881344.00   \n",
       "1   178063.20  2291000.00        0.00    25437.6  1657290.00     1840.00   \n",
       "2   216684.00        0.00   107945.00        0.0   212734.20        0.00   \n",
       "3  5151641.82  4483264.36  5750702.46  5840138.4  5600504.71  5056658.57   \n",
       "4  2580483.11  2084867.32  2585973.88  2979784.8  2366882.52  2361125.47   \n",
       "\n",
       "        Day-7  Prediction  Material_10000001.0  Material_10000002.0  ...  \\\n",
       "0  6101444.00  1329717.00                    1                    0  ...   \n",
       "1     1800.00    17000.00                    0                    1  ...   \n",
       "2   136696.80    57740.25                    0                    0  ...   \n",
       "3  4572115.32  4654375.08                    0                    0  ...   \n",
       "4  2236869.93  2330754.56                    0                    0  ...   \n",
       "\n",
       "   Material_10000031.0  Material_10000032.0  Material_10000033.0  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   Material_10000034.0  Material_10000035.0  Material_10000036.0  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   Material_10000037.0  Material_10000038.0  Material_10000039.0  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   Material_10000040.0  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_1 = pd.concat([dataframe , pd.get_dummies(dataframe['Material'], prefix='Material')],axis=1)\n",
    "try_1.drop(['Material'],axis=1, inplace=True)\n",
    "try_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a606e6c4",
   "metadata": {},
   "source": [
    "### Split Data for RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa45fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X , y , split_size = 0.2):\n",
    "    length = int((1 - split_size) * len(X))\n",
    "    train_data , train_label = X[:length] , y[:length]\n",
    "    test_data , test_label = X[length:] , y[length:]\n",
    "    return train_data , test_data , train_label , test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddc693a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        Day-1       Day-2       Day-3      Day-4       Day-5       Day-6  \\\n",
       " 0   602777.06   274240.00  1553522.60  3843352.0  4205908.00  6881344.00   \n",
       " 1   178063.20  2291000.00        0.00    25437.6  1657290.00     1840.00   \n",
       " 2   216684.00        0.00   107945.00        0.0   212734.20        0.00   \n",
       " 3  5151641.82  4483264.36  5750702.46  5840138.4  5600504.71  5056658.57   \n",
       " 4  2580483.11  2084867.32  2585973.88  2979784.8  2366882.52  2361125.47   \n",
       " \n",
       "         Day-7  Material_10000001.0  Material_10000002.0  Material_10000003.0  \\\n",
       " 0  6101444.00                    1                    0                    0   \n",
       " 1     1800.00                    0                    1                    0   \n",
       " 2   136696.80                    0                    0                    1   \n",
       " 3  4572115.32                    0                    0                    0   \n",
       " 4  2236869.93                    0                    0                    0   \n",
       " \n",
       "    ...  Material_10000031.0  Material_10000032.0  Material_10000033.0  \\\n",
       " 0  ...                    0                    0                    0   \n",
       " 1  ...                    0                    0                    0   \n",
       " 2  ...                    0                    0                    0   \n",
       " 3  ...                    0                    0                    0   \n",
       " 4  ...                    0                    0                    0   \n",
       " \n",
       "    Material_10000034.0  Material_10000035.0  Material_10000036.0  \\\n",
       " 0                    0                    0                    0   \n",
       " 1                    0                    0                    0   \n",
       " 2                    0                    0                    0   \n",
       " 3                    0                    0                    0   \n",
       " 4                    0                    0                    0   \n",
       " \n",
       "    Material_10000037.0  Material_10000038.0  Material_10000039.0  \\\n",
       " 0                    0                    0                    0   \n",
       " 1                    0                    0                    0   \n",
       " 2                    0                    0                    0   \n",
       " 3                    0                    0                    0   \n",
       " 4                    0                    0                    0   \n",
       " \n",
       "    Material_10000040.0  \n",
       " 0                    0  \n",
       " 1                    0  \n",
       " 2                    0  \n",
       " 3                    0  \n",
       " 4                    0  \n",
       " \n",
       " [5 rows x 47 columns],\n",
       " 0    1329717.00\n",
       " 1      17000.00\n",
       " 2      57740.25\n",
       " 3    4654375.08\n",
       " 4    2330754.56\n",
       " Name: Prediction, dtype: float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data , test_data , train_label , test_label = train_test_split(try_1.drop('Prediction' , axis = 1) , try_1['Prediction'])\n",
    "train_data[:5] , train_label[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a834cf0f",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d662a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest_model = RandomForestRegressor(n_estimators = 100, random_state = 0).fit(train_data , train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8df1453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_forest_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df76ec8",
   "metadata": {},
   "source": [
    "### Error handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f0c18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors(y_true , y_pred):\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    y_new = np.abs(y_true - y_pred)\n",
    "    median = np.median(y_new)\n",
    "    mae = tf.keras.metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = tf.keras.metrics.mean_squared_error(y_true, y_pred) # puts and emphasis on outliers (all errors get squared)\n",
    "    rmse = tf.sqrt(mse)\n",
    "    mape = tf.keras.metrics.mean_absolute_percentage_error(y_true, y_pred)\n",
    "    y_new2 = np.zeros(len(y_new))\n",
    "    for i in range(len(y_new)):\n",
    "        if(y_true[i] != 0):\n",
    "            y_new2[i] = y_new[i] / y_true[i] * 100\n",
    "    median_per = np.median(y_new2)\n",
    "    mean_per = np.mean(y_new2)\n",
    "    maxi = np.amax(y_new2)\n",
    "    mini = np.amin(y_new2)\n",
    "    \n",
    "    return {'MAE: ' : mae.numpy() , 'MSE' : mse.numpy() , 'RMSE' : rmse.numpy() ,\n",
    "            'MAPE' : mape.numpy() , 'Median' : median , '% error wrt median' : median_per , '% error wrt mean' : mean_per , \n",
    "           'Min% Error' : mini , 'Max% Error' : maxi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3e49a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2688      88287.00\n",
       " 2689    4399137.02\n",
       " 2690    1007368.34\n",
       " 2691    3480342.96\n",
       " 2692    2186020.23\n",
       " Name: Prediction, dtype: float64,\n",
       " array([ 165734.4024, 3808046.3818,  980483.5034, 3100322.7774,\n",
       "         774772.8538]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label[:5] , y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "484d8de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE: ': 325523.56, 'MSE': 504076140000.0, 'RMSE': 709983.2, 'MAPE': 6736443300000.0, 'Median': 122858.97, '% error wrt median': 12.223315238952637, '% error wrt mean': 67.80606888112379, 'Min% Error': 0.0, 'Max% Error': 10775.12109375}\n"
     ]
    }
   ],
   "source": [
    "random_forest_error = errors(tf.squeeze(test_label) , y_pred)\n",
    "print(random_forest_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbfa311",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "830bea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_model = LinearRegression().fit(train_data , train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2438ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0d544fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE: ': 380650.16, 'MSE': 597689700000.0, 'RMSE': 773103.94, 'MAPE': 6064724000000.0, 'Median': 170755.69, '% error wrt median': 17.3764705657959, '% error wrt mean': 54.25746817816461, 'Min% Error': 0.0, 'Max% Error': 4515.06591796875}\n"
     ]
    }
   ],
   "source": [
    "linear_error = errors(tf.squeeze(test_label) , y_pred)\n",
    "print(linear_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ae6cf",
   "metadata": {},
   "source": [
    "## KNN regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a850c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_model = KNeighborsRegressor().fit(train_data , train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70142e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33b7897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE: ': 336379.78, 'MSE': 547696480000.0, 'RMSE': 740065.2, 'MAPE': 7767849400000.0, 'Median': 129801.28, '% error wrt median': 13.562328338623047, '% error wrt mean': 64.83044506850862, 'Min% Error': 0.0, 'Max% Error': 7342.72216796875}\n"
     ]
    }
   ],
   "source": [
    "knn_error = errors(tf.squeeze(test_label) , y_pred)\n",
    "print(knn_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b021fa",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79c21b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decision_model = DecisionTreeRegressor().fit(train_data , train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd27346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decision_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66ca4a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE: ': 468124.16, 'MSE': 1045385700000.0, 'RMSE': 1022441.06, 'MAPE': 5603156600000.0, 'Median': 151400.06, '% error wrt median': 17.467209815979004, '% error wrt mean': 121.92656634527347, 'Min% Error': 0.0, 'Max% Error': 37454.59765625}\n"
     ]
    }
   ],
   "source": [
    "decision_error = errors(tf.squeeze(test_label) , y_pred)\n",
    "print(decision_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1917fcb",
   "metadata": {},
   "source": [
    "## Data preparation for Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "445b44e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.0277706e+05, 2.7424000e+05, 1.5535226e+06, 3.8433520e+06,\n",
       "         4.2059080e+06, 6.8813440e+06, 6.1014440e+06, 1.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [1.7806320e+05, 2.2910000e+06, 0.0000000e+00, 2.5437600e+04,\n",
       "         1.6572900e+06, 1.8400000e+03, 1.8000000e+03, 0.0000000e+00,\n",
       "         1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [2.1668400e+05, 0.0000000e+00, 1.0794500e+05, 0.0000000e+00,\n",
       "         2.1273420e+05, 0.0000000e+00, 1.3669680e+05, 0.0000000e+00,\n",
       "         0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]),\n",
       " array([1329717.  ,   17000.  ,   57740.25]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data into numpy so that tensorflow can make appropriate changes\n",
    "full_window = try_1.drop('Prediction' , axis = 1).to_numpy()\n",
    "full_label = try_1['Prediction'].to_numpy()\n",
    "full_window[:3] , full_label[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfd40da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[9.54748400e+04, 3.69052430e+05, 1.46352920e+05, 1.93992620e+05,\n",
       "         1.10628290e+05, 5.36643600e+04, 7.32431900e+04, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [4.09295942e+06, 4.27619482e+06, 2.89048911e+06, 4.36516361e+06,\n",
       "         4.55561279e+06, 3.74795096e+06, 4.43930803e+06, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [9.62939720e+05, 9.56462490e+05, 8.71577560e+05, 9.14195610e+05,\n",
       "         1.13441237e+06, 9.66718610e+05, 1.12178800e+06, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       " array([  88287.  , 4399137.02, 1007368.34]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data , test_data , train_label , test_label = train_test_split(full_window , full_label)\n",
    "test_data[:3] , test_label[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a036124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a function to implement a ModelCheckpoint callback with a specific filename \n",
    "def create_model_checkpoint(model_name, save_path=\"model_experiments\"):\n",
    "    return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path, model_name), # create filepath to save model\n",
    "                                            verbose=0, # only output a limited amount of text\n",
    "                                            save_best_only=True) # save only the best model to file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc6345c",
   "metadata": {},
   "source": [
    "## Tiny Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "addc485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 4s 56ms/step - loss: 1391106.3750 - val_loss: 1280156.7500\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 590073.3125 - val_loss: 322907.3438\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 281580.0625 - val_loss: 328089.0625\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 264800.2812 - val_loss: 303672.8750\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 253122.8594 - val_loss: 313490.4375\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 254879.3750 - val_loss: 310468.3438\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 251919.5469 - val_loss: 308408.0312\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 248718.4219 - val_loss: 307351.1250\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 247053.4688 - val_loss: 304683.8438\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 243121.0000 - val_loss: 303172.5625\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 242260.0938 - val_loss: 303347.9375\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 240514.1406 - val_loss: 302120.6875\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 241228.7344 - val_loss: 300334.0938\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 239920.8594 - val_loss: 305916.4375\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 237027.9531 - val_loss: 301717.2500\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 237922.7656 - val_loss: 299599.7500\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 236566.8125 - val_loss: 302313.6250\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 236771.2812 - val_loss: 307576.4375\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 236059.0469 - val_loss: 307019.8438\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 236060.6406 - val_loss: 305034.0000\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 235248.2812 - val_loss: 297537.7500\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 234754.2188 - val_loss: 303559.2500\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 233963.8750 - val_loss: 295759.8125\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 236662.9531 - val_loss: 298221.9062\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 233227.7812 - val_loss: 295333.6562\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 230981.2344 - val_loss: 294036.6562\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 232325.2656 - val_loss: 300555.4062\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 234093.3125 - val_loss: 294709.0000\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 230107.9531 - val_loss: 295135.7500\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 229420.6875 - val_loss: 295918.4375\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 229616.5000 - val_loss: 301447.7500\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 231099.3750 - val_loss: 296655.0312\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 228217.0781 - val_loss: 299301.0000\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 228102.2812 - val_loss: 295264.6562\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 228043.4531 - val_loss: 295195.2812\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 229646.9688 - val_loss: 295074.0625\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 228378.5000 - val_loss: 295773.7812\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 227537.0781 - val_loss: 294204.3125\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 226352.7188 - val_loss: 297443.4375\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 226114.2344 - val_loss: 298645.5312\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 225662.5469 - val_loss: 297222.5625\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 225636.7188 - val_loss: 294492.1875\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 226098.5938 - val_loss: 294022.0000\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 227540.2344 - val_loss: 301591.1250\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 225762.8594 - val_loss: 293484.3438\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 224858.7344 - val_loss: 292995.9375\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 225119.9688 - val_loss: 302155.0312\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 224559.2344 - val_loss: 294420.1875\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 223479.0781 - val_loss: 292494.4375\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 223651.4062 - val_loss: 292371.4688\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 222834.7344 - val_loss: 292551.7188\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 224074.3125 - val_loss: 299638.6875\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 225906.8281 - val_loss: 294267.4375\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 223024.3750 - val_loss: 298806.4375\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 222611.0469 - val_loss: 303375.2188\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 224234.5781 - val_loss: 294653.8750\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 223334.8125 - val_loss: 291567.1250\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 222346.1875 - val_loss: 295897.4062\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 222530.1875 - val_loss: 294903.7812\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 222172.2812 - val_loss: 294472.8438\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 224220.3750 - val_loss: 316100.4062\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 223342.4531 - val_loss: 292167.6562\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 220824.6406 - val_loss: 298781.5625\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 221511.8594 - val_loss: 292109.6875\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 220591.8750 - val_loss: 293762.2812\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 220378.2344 - val_loss: 291574.1562\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 221044.9062 - val_loss: 300259.8438\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 219656.8125 - val_loss: 290666.1562\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 220571.3594 - val_loss: 292002.1875\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 219421.8750 - val_loss: 296517.5312\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 223010.4531 - val_loss: 292042.0625\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 220035.1406 - val_loss: 289161.5000\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 218976.8281 - val_loss: 289187.7500\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 219083.5469 - val_loss: 294065.0312\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 219709.1406 - val_loss: 294878.4375\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 223418.9062 - val_loss: 293771.8438\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 220838.7188 - val_loss: 292695.9062\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 218065.6406 - val_loss: 291915.7188\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 222736.6406 - val_loss: 290566.3750\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 217548.8281 - val_loss: 291281.4688\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 217795.7344 - val_loss: 291441.3438\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 217652.5312 - val_loss: 288653.1562\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 219713.9531 - val_loss: 294824.5000\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 218467.4688 - val_loss: 289342.4062\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 219485.8750 - val_loss: 293654.0625\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 220311.0781 - val_loss: 289463.9062\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 218791.3594 - val_loss: 291803.8750\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 216889.5312 - val_loss: 290058.3125\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 217729.1406 - val_loss: 289003.1562\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 221073.0938 - val_loss: 291487.8125\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 218154.9219 - val_loss: 288797.6875\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 215739.67 - 0s 5ms/step - loss: 215904.7812 - val_loss: 294751.0938\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 216515.3594 - val_loss: 288844.1250\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 217916.5781 - val_loss: 296343.1250\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 215812.3281 - val_loss: 291298.0938\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 216340.8281 - val_loss: 291486.5938\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 215604.9688 - val_loss: 288775.8438\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 215942.3125 - val_loss: 294688.1875\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 215798.6875 - val_loss: 295824.7188\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 216834.9531 - val_loss: 293471.3438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2034677a910>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "tiny_model = tf.keras.Sequential([\n",
    "    layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) ,\n",
    "    layers.GRU(100 , activation = 'relu') , \n",
    "    layers.Dense(1 , activation = 'relu')\n",
    "] , name = 'Tiny_Model')\n",
    "\n",
    "tiny_model.compile(loss = tf.keras.losses.mae , optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "tiny_model.fit(x = train_data , y = train_label , epochs = 100 , batch_size = 128 , \n",
    "               validation_data = (test_data , test_label) , \n",
    "               callbacks=[create_model_checkpoint(model_name=tiny_model.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e9fa1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(model, input_data):\n",
    "    forecast = model.predict(input_data)\n",
    "    return tf.squeeze(forecast) # return 1D array of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79c84468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 1ms/step - loss: 288653.1562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "288653.15625"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_model = tf.keras.models.load_model(\"model_experiments/Tiny_Model/\")\n",
    "tiny_model.evaluate(test_data , test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36c02aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([  91930.12, 4379104.5 , 1041325.56, 3238549.5 ,  593057.2 ,\n",
       "        146896.47, 2380032.5 , 2657306.  , 3210694.8 , 2018606.8 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_model_preds = make_preds(tiny_model , test_data)\n",
    "tiny_model_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ccc1a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE: ': 288653.1, 'MSE': 448565540000.0, 'RMSE': 669750.4, 'MAPE': 4344638300000.0, 'Median': 127747.31, '% error wrt median': 11.82497787475586, '% error wrt mean': 35.671258092913334, 'Min% Error': 0.0, 'Max% Error': 2126.05517578125}\n"
     ]
    }
   ],
   "source": [
    "tiny_model_error = errors(test_label , tiny_model_preds)\n",
    "print(tiny_model_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2420a",
   "metadata": {},
   "source": [
    "## Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf86eccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 2s 27ms/step - loss: 1290508.6250 - val_loss: 861932.3750\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 367507.9375 - val_loss: 354223.6250\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 270722.2812 - val_loss: 319959.4062\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 254857.1719 - val_loss: 309422.2500\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 255880.7656 - val_loss: 319709.0625\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 244752.8125 - val_loss: 304845.3438\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 237072.9531 - val_loss: 307021.8750\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 236731.1875 - val_loss: 299458.9375\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 233462.6875 - val_loss: 296374.2500\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 232519.9531 - val_loss: 302954.5312\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 235004.7188 - val_loss: 296644.9062\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 229501.6406 - val_loss: 298952.2500\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 229883.1875 - val_loss: 297785.7812\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 229301.6875 - val_loss: 306579.2188\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 229075.7656 - val_loss: 295345.1562\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 227249.2188 - val_loss: 291885.6250\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 226343.5781 - val_loss: 312109.4062\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 230748.2812 - val_loss: 312755.0312\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 227049.2188 - val_loss: 301787.1562\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 222384.6250 - val_loss: 296827.5625\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 222488.3125 - val_loss: 296281.0000\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 221677.4219 - val_loss: 291816.3438\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 223914.0312 - val_loss: 297941.7812\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 223965.0312 - val_loss: 294042.7500\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 220507.5469 - val_loss: 293129.2188\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 225575.2188 - val_loss: 318470.0938\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 231794.9531 - val_loss: 304725.6562\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 223912.7656 - val_loss: 302634.8750\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 219504.2812 - val_loss: 298141.8125\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 214425.3750 - val_loss: 302769.6562\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 217564.2188 - val_loss: 294249.6562\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 215613.5938 - val_loss: 293861.5625\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 212664.0312 - val_loss: 302087.9375\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 218658.2812 - val_loss: 300313.5312\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 211674.6406 - val_loss: 296278.7500\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 211097.5781 - val_loss: 300246.0312\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 209645.5312 - val_loss: 296371.7188\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 208860.7656 - val_loss: 300941.4375\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 208436.2812 - val_loss: 297892.7500\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 209581.6406 - val_loss: 315204.9062\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 209372.6719 - val_loss: 296168.5625\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 208776.3281 - val_loss: 301221.1875\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 205734.4062 - val_loss: 297334.3438\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 204790.7656 - val_loss: 301624.8438\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 207356.4062 - val_loss: 305465.6562\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 207024.9688 - val_loss: 300809.1875\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 203761.5000 - val_loss: 301416.4375\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 206661.4531 - val_loss: 302068.1562\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 206188.2344 - val_loss: 301506.3750\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 201563.0000 - val_loss: 302458.7812\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 201434.1875 - val_loss: 309521.1562\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 206080.4531 - val_loss: 310874.8125\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 201270.4531 - val_loss: 304736.4375\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 199065.2812 - val_loss: 310485.7812\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 199515.5781 - val_loss: 303185.5000\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 204477.1406 - val_loss: 308191.5625\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 222562.82 - 0s 3ms/step - loss: 205405.4219 - val_loss: 326551.7500\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 198852.8750 - val_loss: 325075.6562\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 200703.5781 - val_loss: 315540.6562\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 196213.8906 - val_loss: 315555.6562\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 198165.1094 - val_loss: 312933.0625\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 194297.2188 - val_loss: 305082.1562\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 197922.4688 - val_loss: 306827.0938\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 194999.1094 - val_loss: 313084.4375\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 193140.9688 - val_loss: 308302.8438\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 196707.5156 - val_loss: 320954.7500\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 194275.1562 - val_loss: 311682.2500\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 196758.1250 - val_loss: 309337.1250\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 198955.6719 - val_loss: 310078.0312\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 193026.9219 - val_loss: 311610.6562\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 191753.4531 - val_loss: 308395.0000\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 194064.0781 - val_loss: 309219.7500\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 193146.1875 - val_loss: 314316.6875\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 203831.2656 - val_loss: 334115.2500\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 193851.4688 - val_loss: 307010.6875\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 192197.2812 - val_loss: 308427.6562\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 190605.2344 - val_loss: 307557.0625\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 192310.4688 - val_loss: 315878.4688\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 192402.2188 - val_loss: 314555.7188\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 190437.8125 - val_loss: 318743.9375\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 189282.2969 - val_loss: 311183.9375\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 195764.1406 - val_loss: 312558.5625\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 191411.0781 - val_loss: 313180.6875\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 193505.9844 - val_loss: 316419.3438\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 191568.8906 - val_loss: 322580.0625\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 192077.1094 - val_loss: 319208.7500\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 188690.2812 - val_loss: 314348.3750\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 186759.2812 - val_loss: 313936.1562\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 188624.0781 - val_loss: 313271.1562\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 183827.3906 - val_loss: 309450.4062\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 189040.5938 - val_loss: 317580.7500\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 189887.1719 - val_loss: 311956.2188\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 187319.4531 - val_loss: 312043.8750\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 185021.1094 - val_loss: 308950.9375\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 181889.5000 - val_loss: 310469.3750\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 189880.4375 - val_loss: 335896.7500\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 185516.9219 - val_loss: 323415.3750\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 185876.1719 - val_loss: 315706.7188\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 182810.5781 - val_loss: 314735.5625\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 182938.2969 - val_loss: 318843.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2034843de50>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model = tf.keras.Sequential([\n",
    "    layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) ,\n",
    "    layers.GRU(100 , activation = 'relu') , \n",
    "    layers.Dense(100 , activation = 'relu') , \n",
    "    layers.Dense(1 , activation = 'relu')\n",
    "] , name = 'Small_Model')\n",
    "\n",
    "small_model.compile(loss = tf.keras.losses.mae , optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "small_model.fit(x = train_data , y = train_label , epochs = 100 , batch_size = 128 , \n",
    "               validation_data = (test_data , test_label) , \n",
    "               callbacks=[create_model_checkpoint(model_name = small_model.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b5e20b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 1ms/step - loss: 291816.3438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "291816.34375"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model = tf.keras.models.load_model(\"model_experiments/Small_Model/\")\n",
    "small_model.evaluate(test_data , test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78e136c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 120436.85, 4298189.  , 1047580.75, 3283566.2 ,  632553.  ,\n",
       "        161867.02, 2402131.5 , 2703639.5 , 3241084.2 , 1990949.6 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model_preds = make_preds(small_model , test_data)\n",
    "small_model_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e90ea92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE: ': 291816.34, 'MSE': 468630800000.0, 'RMSE': 684566.1, 'MAPE': 3976355000000.0, 'Median': 121306.69, '% error wrt median': 11.398791313171387, '% error wrt mean': 38.17374804389626, 'Min% Error': 0.0, 'Max% Error': 2515.488037109375}\n"
     ]
    }
   ],
   "source": [
    "small_model_error = errors(test_label , small_model_preds)\n",
    "print(small_model_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6867d",
   "metadata": {},
   "source": [
    "## Medium Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0153b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 3s 46ms/step - loss: 553994.1875 - val_loss: 371529.3750\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 275421.1562 - val_loss: 315519.4375\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 252621.2344 - val_loss: 302130.0625\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 240289.1719 - val_loss: 309931.5312\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 240800.2656 - val_loss: 302620.0000\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 241632.2656 - val_loss: 296728.2500\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 235206.1250 - val_loss: 308606.0938\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 228895.9062 - val_loss: 359968.4062\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 233340.0000 - val_loss: 311142.2188\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 226877.2656 - val_loss: 305918.3125\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 221584.8594 - val_loss: 301322.4688\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 232524.4688 - val_loss: 373920.7188\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 234672.8594 - val_loss: 298472.9375\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 220948.3750 - val_loss: 310209.1562\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 215757.0312 - val_loss: 302265.6875\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 220551.0000 - val_loss: 305075.3438\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 211321.6250 - val_loss: 299178.3125\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 211701.4219 - val_loss: 307550.6875\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 211272.5781 - val_loss: 301012.8438\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 209604.4062 - val_loss: 342617.9062\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 216879.6406 - val_loss: 297014.5312\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 206192.8594 - val_loss: 295939.5000\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 205673.3281 - val_loss: 306757.1562\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 204493.2344 - val_loss: 296573.9062\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 208108.1406 - val_loss: 314299.3438\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 210624.6875 - val_loss: 340743.0312\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 210556.6719 - val_loss: 302188.0625\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 206866.8281 - val_loss: 301963.8438\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 222635.2812 - val_loss: 308337.6562\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 206250.2812 - val_loss: 305664.0625\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 204608.9062 - val_loss: 337817.0000\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 212159.0312 - val_loss: 313071.4375\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 199734.4531 - val_loss: 328911.0625\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 198419.2812 - val_loss: 330822.6250\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 209312.5781 - val_loss: 311617.0000\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 199518.3125 - val_loss: 320952.3750\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 204561.9688 - val_loss: 322665.5000\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 200147.3281 - val_loss: 320794.2500\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 199157.1719 - val_loss: 317087.6875\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 190814.8594 - val_loss: 308096.2812\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 192878.5469 - val_loss: 313498.1250\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 193288.4219 - val_loss: 309842.0938\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 190692.1250 - val_loss: 319951.7188\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 193900.1875 - val_loss: 307933.1250\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 192329.0000 - val_loss: 306872.2500\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 188353.3281 - val_loss: 308481.7500\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 187621.8281 - val_loss: 314161.4062\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 190706.7969 - val_loss: 321686.4375\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 201958.8125 - val_loss: 352795.8125\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 191178.9219 - val_loss: 314959.3750\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 189361.2188 - val_loss: 317837.9375\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 184675.2969 - val_loss: 311834.4375\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 184066.5000 - val_loss: 317479.9688\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 185224.4531 - val_loss: 318922.6875\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 184891.0469 - val_loss: 313183.8438\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 186919.0312 - val_loss: 326571.3438\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 204509.2188 - val_loss: 316606.1562\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 196478.1406 - val_loss: 314898.9375\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 198759.1250 - val_loss: 315582.0312\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 192192.6562 - val_loss: 328204.1250\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 193218.7812 - val_loss: 330875.8438\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 189895.0781 - val_loss: 339468.0625\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 185863.6094 - val_loss: 325812.0938\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 185222.2344 - val_loss: 337284.9688\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 185549.4531 - val_loss: 331399.0312\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 185896.1562 - val_loss: 324541.4688\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 186716.4062 - val_loss: 327909.4375\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 190220.7656 - val_loss: 319724.1562\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 178795.0156 - val_loss: 333916.2812\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 182537.2188 - val_loss: 322673.6562\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 180836.8281 - val_loss: 323556.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 181292.8750 - val_loss: 334421.5000\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 180827.9375 - val_loss: 325392.7500\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 186146.1250 - val_loss: 320633.7500\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 179216.1719 - val_loss: 322654.0312\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 177632.7188 - val_loss: 321789.3438\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 184887.5312 - val_loss: 375437.2500\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 192228.0469 - val_loss: 328352.5000\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 181226.1094 - val_loss: 316194.6562\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 179112.3125 - val_loss: 315478.7500\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 181378.5781 - val_loss: 321376.7188\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 175053.2500 - val_loss: 323298.6562\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 184632.9219 - val_loss: 381551.2500\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 181724.0156 - val_loss: 323254.6250\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 175122.2656 - val_loss: 327874.8750\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 180569.4844 - val_loss: 324036.4688\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 174502.0938 - val_loss: 321943.5625\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 176168.8906 - val_loss: 331660.3750\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 175691.1250 - val_loss: 317558.8438\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 174962.2188 - val_loss: 321802.9062\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 175568.3438 - val_loss: 333107.5000\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 176692.4531 - val_loss: 322558.5625\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 171368.5312 - val_loss: 319883.9375\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 175579.6562 - val_loss: 325560.8438\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 172336.5469 - val_loss: 332698.6562\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 182822.0312 - val_loss: 327006.9375\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 174183.4375 - val_loss: 321153.9375\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 170317.0312 - val_loss: 315331.2500\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 170111.1250 - val_loss: 326035.3438\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 171103.0938 - val_loss: 339974.0625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20345b6e970>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_model = tf.keras.Sequential([\n",
    "    layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) ,\n",
    "    layers.GRU(300 , activation = 'relu') , \n",
    "    layers.Dense(300 , activation = 'relu') , \n",
    "    layers.Dense(300 , activation = 'relu') , \n",
    "    layers.Dense(1 , activation = 'relu')\n",
    "] , name = 'Medium_Model')\n",
    "\n",
    "medium_model.compile(loss = tf.keras.losses.mae , optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "medium_model.fit(x = train_data , y = train_label , epochs = 100 , batch_size = 128 , \n",
    "               validation_data = (test_data , test_label) , \n",
    "               callbacks=[create_model_checkpoint(model_name = medium_model.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33d71895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 295939.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "295939.5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_model = tf.keras.models.load_model(\"model_experiments/Medium_Model/\")\n",
    "medium_model.evaluate(test_data , test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d482db58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 140351.34, 4195686.5 , 1012793.06, 3111692.  ,  588435.2 ,\n",
       "        166307.12, 2375709.  , 2674264.2 , 3155124.2 , 1970093.1 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_model_preds = make_preds(medium_model , test_data)\n",
    "medium_model_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4df14f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE: ': 295939.47, 'MSE': 464838030000.0, 'RMSE': 681790.3, 'MAPE': 3200608400000.0, 'Median': 117846.61, '% error wrt median': 12.643126487731934, '% error wrt mean': 35.90661502492592, 'Min% Error': 0.0, 'Max% Error': 2108.390625}\n"
     ]
    }
   ],
   "source": [
    "medium_model_error = errors(test_label , medium_model_preds)\n",
    "print(medium_model_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f20eb",
   "metadata": {},
   "source": [
    "## Large Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad14d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 2s 46ms/step - loss: 441616.6562 - val_loss: 323460.7188\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 270062.9062 - val_loss: 328845.0000\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 238708.0312 - val_loss: 302950.3438\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 249283.4062 - val_loss: 299307.7812\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 257007.8594 - val_loss: 295417.8125\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 257309.6250 - val_loss: 308396.0938\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 241183.2812 - val_loss: 344087.2500\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 236071.3281 - val_loss: 300980.9375\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 227107.4688 - val_loss: 293312.0312\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 222790.0938 - val_loss: 296737.5938\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 219821.6719 - val_loss: 319097.4688\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 232743.2812 - val_loss: 320444.9062\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 222623.2812 - val_loss: 289971.7500\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 216973.6406 - val_loss: 310487.6562\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 221243.8750 - val_loss: 297338.5625\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 223515.3594 - val_loss: 300924.8750\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 216610.1719 - val_loss: 312616.3438\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 215835.3125 - val_loss: 308347.1875\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 216639.0469 - val_loss: 324049.5000\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 214634.6406 - val_loss: 310666.3750\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 212261.0938 - val_loss: 311860.6250\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 212587.0312 - val_loss: 336870.0000\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 209080.9688 - val_loss: 356490.9375\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 214199.7812 - val_loss: 310807.2188\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 212925.3281 - val_loss: 316516.6562\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 213004.2344 - val_loss: 311794.6875\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 207349.0781 - val_loss: 312793.2812\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 203323.5781 - val_loss: 333428.3438\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 233667.7344 - val_loss: 358051.9375\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 207185.7188 - val_loss: 352306.4688\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 203979.5781 - val_loss: 320393.0000\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 196509.8750 - val_loss: 312186.6875\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 195199.3281 - val_loss: 314233.8125\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 199084.6719 - val_loss: 303072.2188\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 193441.7031 - val_loss: 304608.5312\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 197588.6250 - val_loss: 302950.5625\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 197343.8906 - val_loss: 323478.2500\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 200138.6875 - val_loss: 310754.5625\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 229103.5000 - val_loss: 333895.4688\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 197478.2656 - val_loss: 336700.3125\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 195192.7656 - val_loss: 318022.7812\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 193818.8125 - val_loss: 354376.5312\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 205434.9688 - val_loss: 356468.6250\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 196403.5625 - val_loss: 339351.6562\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 192684.2344 - val_loss: 329107.7500\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 192077.3750 - val_loss: 319692.2500\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 186410.5781 - val_loss: 318536.5625\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 190052.9219 - val_loss: 326665.4688\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 209592.1719 - val_loss: 397471.4688\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 199441.2188 - val_loss: 322290.0000\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 186533.1406 - val_loss: 338065.5000\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 185423.6406 - val_loss: 332723.6562\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 182789.3594 - val_loss: 316622.6250\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 185460.3281 - val_loss: 333289.4688\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 180856.2500 - val_loss: 326175.8750\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 184135.1875 - val_loss: 316940.4062\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 181744.3750 - val_loss: 316308.4375\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 184828.2188 - val_loss: 360318.0625\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 183951.3281 - val_loss: 321096.9062\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 180965.7812 - val_loss: 325020.5312\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 176119.8594 - val_loss: 328188.1250\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 191074.4219 - val_loss: 317669.0938\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 181936.0938 - val_loss: 351510.7188\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 191439.7500 - val_loss: 321388.6562\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 174478.3125 - val_loss: 336290.5625\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 173702.0625 - val_loss: 312735.6250\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 178669.9688 - val_loss: 333776.0625\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 174462.0781 - val_loss: 354932.2812\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 173363.3750 - val_loss: 327633.7188\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 193801.9062 - val_loss: 345439.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 183889.4688 - val_loss: 340597.9062\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 175192.2188 - val_loss: 313779.7500\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 171618.0625 - val_loss: 312768.5312\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 175293.7344 - val_loss: 385203.6875\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 178925.3281 - val_loss: 320924.2812\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 171810.9688 - val_loss: 318472.5312\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 167162.1719 - val_loss: 318014.7188\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 168496.6875 - val_loss: 331437.1562\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 167463.9219 - val_loss: 320328.3438\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 171853.9531 - val_loss: 328551.6250\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 167215.7656 - val_loss: 313960.2500\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 168196.7188 - val_loss: 323959.6250\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 185107.0000 - val_loss: 315528.9688\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 165698.1250 - val_loss: 336526.7188\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 171409.9219 - val_loss: 322112.4062\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 170811.8750 - val_loss: 332136.2500\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 168585.9844 - val_loss: 312878.4062\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 166168.4062 - val_loss: 323254.0625\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 166079.0781 - val_loss: 322904.5000\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 166116.2812 - val_loss: 324260.7500\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 177973.0469 - val_loss: 345984.6562\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 164811.3906 - val_loss: 317588.8438\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 164079.9062 - val_loss: 315128.4688\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 167505.0625 - val_loss: 322677.6562\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 157243.3438 - val_loss: 314849.2500\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 161763.6250 - val_loss: 320231.7500\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 172876.7969 - val_loss: 345194.7500\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 172577.1406 - val_loss: 328605.0625\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 169068.6250 - val_loss: 323026.9375\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 173463.5781 - val_loss: 314241.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20389a750d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_model = tf.keras.Sequential([\n",
    "    layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) ,\n",
    "    layers.GRU(512 , activation = 'relu') , \n",
    "    layers.Dense(512 , activation = 'relu') , \n",
    "    layers.Dense(512 , activation = 'relu') ,\n",
    "    layers.Dense(512 , activation = 'relu') ,\n",
    "    layers.Dense(1 , activation = 'relu')\n",
    "] , name = 'Large_Model')\n",
    "\n",
    "large_model.compile(loss = tf.keras.losses.mae , optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "large_model.fit(x = train_data , y = train_label , epochs = 100 , batch_size = 128 , \n",
    "               validation_data = (test_data , test_label) , \n",
    "               callbacks=[create_model_checkpoint(model_name = large_model.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b294485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 289971.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "289971.75"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_model = tf.keras.models.load_model(\"model_experiments/Large_Model/\")\n",
    "large_model.evaluate(test_data , test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1ce5b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 160183.72, 4393987.5 , 1051853.6 , 3290068.8 ,  582309.9 ,\n",
       "        161637.78, 2425424.8 , 2741735.5 , 3254214.8 , 2005247.  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_model_preds = make_preds(large_model , test_data)\n",
    "large_model_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b6c6e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE: ': 289971.75, 'MSE': 459039000000.0, 'RMSE': 677524.2, 'MAPE': 3285335100000.0, 'Median': 112827.92, '% error wrt median': 11.359111785888672, '% error wrt mean': 42.61673978938017, 'Min% Error': 0.0, 'Max% Error': 2509.044189453125}\n"
     ]
    }
   ],
   "source": [
    "large_model_error = errors(test_label , large_model_preds)\n",
    "print(large_model_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eab22f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Create a function to plot time series data\n",
    "def plot_time_series(timesteps, values, format='.', start=0, end=None, label=None):\n",
    "  # Plot the series\n",
    "    plt.plot(timesteps[start:end], values[start:end], format, label=label)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    if label:\n",
    "        plt.legend(fontsize=14) # make label bigger\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a31d4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_lower(y_true , y_pred):\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    upper = y_pred + (y_pred*15/100)\n",
    "    lower = y_pred - (y_pred*15/100)\n",
    "    return upper , lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b012495e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Value</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Upper</th>\n",
       "      <th>Lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88287.00</td>\n",
       "      <td>1.384496e+05</td>\n",
       "      <td>1.592170e+05</td>\n",
       "      <td>1.176821e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4399137.02</td>\n",
       "      <td>4.363432e+06</td>\n",
       "      <td>5.017946e+06</td>\n",
       "      <td>3.708917e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007368.34</td>\n",
       "      <td>1.035585e+06</td>\n",
       "      <td>1.190923e+06</td>\n",
       "      <td>8.802476e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3480342.96</td>\n",
       "      <td>3.099590e+06</td>\n",
       "      <td>3.564529e+06</td>\n",
       "      <td>2.634652e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2186020.23</td>\n",
       "      <td>6.116046e+05</td>\n",
       "      <td>7.033453e+05</td>\n",
       "      <td>5.198639e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   True Value    Prediction         Upper         Lower\n",
       "0    88287.00  1.384496e+05  1.592170e+05  1.176821e+05\n",
       "1  4399137.02  4.363432e+06  5.017946e+06  3.708917e+06\n",
       "2  1007368.34  1.035585e+06  1.190923e+06  8.802476e+05\n",
       "3  3480342.96  3.099590e+06  3.564529e+06  2.634652e+06\n",
       "4  2186020.23  6.116046e+05  7.033453e+05  5.198639e+05"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper , lower = upper_lower(test_label , combined_model_preds)\n",
    "dictionary = {'True Value' : test_label , 'Prediction' : combined_model_preds , 'Upper' : upper , 'Lower' : lower}\n",
    "datas = pd.DataFrame(dictionary)\n",
    "datas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bfe8c1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Value</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Upper</th>\n",
       "      <th>Lower</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88287.00</td>\n",
       "      <td>1.384496e+05</td>\n",
       "      <td>1.592170e+05</td>\n",
       "      <td>1.176821e+05</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4399137.02</td>\n",
       "      <td>4.363432e+06</td>\n",
       "      <td>5.017946e+06</td>\n",
       "      <td>3.708917e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007368.34</td>\n",
       "      <td>1.035585e+06</td>\n",
       "      <td>1.190923e+06</td>\n",
       "      <td>8.802476e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3480342.96</td>\n",
       "      <td>3.099590e+06</td>\n",
       "      <td>3.564529e+06</td>\n",
       "      <td>2.634652e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2186020.23</td>\n",
       "      <td>6.116046e+05</td>\n",
       "      <td>7.033453e+05</td>\n",
       "      <td>5.198639e+05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   True Value    Prediction         Upper         Lower  Outlier\n",
       "0    88287.00  1.384496e+05  1.592170e+05  1.176821e+05     -1.0\n",
       "1  4399137.02  4.363432e+06  5.017946e+06  3.708917e+06      NaN\n",
       "2  1007368.34  1.035585e+06  1.190923e+06  8.802476e+05      NaN\n",
       "3  3480342.96  3.099590e+06  3.564529e+06  2.634652e+06      NaN\n",
       "4  2186020.23  6.116046e+05  7.033453e+05  5.198639e+05      1.0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(datas)):\n",
    "    if(datas.iloc[i].loc['Upper'] < datas.iloc[i].loc['True Value']):\n",
    "        datas.loc[i , 'Outlier'] = 1\n",
    "    \n",
    "    elif(datas.iloc[i].loc['Lower'] > datas.iloc[i].loc['True Value']):\n",
    "        datas.loc[i , 'Outlier'] = -1\n",
    "        \n",
    "datas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e83a4f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    }
   ],
   "source": [
    "up = datas.where(datas['Outlier'] > 0)\n",
    "up.dropna(subset = [\"Outlier\"] , inplace=True)\n",
    "print(len(up))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "327b5e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "down = datas.where(datas['Outlier'] < 0)\n",
    "down.dropna(subset = [\"Outlier\"], inplace=True)\n",
    "print(len(down))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e2aed",
   "metadata": {},
   "source": [
    "## Stack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "04bbf622",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model_preds = (small_model_preds + medium_model_preds + large_model_preds) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "94804d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.02777060e+05, 2.74240000e+05, 1.55352260e+06, ...,\n",
       "        4.20590800e+06, 6.88134400e+06, 6.10144400e+06],\n",
       "       [1.78063200e+05, 2.29100000e+06, 0.00000000e+00, ...,\n",
       "        1.65729000e+06, 1.84000000e+03, 1.80000000e+03],\n",
       "       [2.16684000e+05, 0.00000000e+00, 1.07945000e+05, ...,\n",
       "        2.12734200e+05, 0.00000000e+00, 1.36696800e+05],\n",
       "       ...,\n",
       "       [3.20160996e+06, 2.89466561e+06, 2.13520424e+06, ...,\n",
       "        3.66557960e+06, 3.71931443e+06, 3.23460348e+06],\n",
       "       [9.18454080e+05, 8.74652700e+05, 4.64518930e+05, ...,\n",
       "        1.00193220e+06, 1.00426506e+06, 8.83992330e+05],\n",
       "       [9.71937060e+05, 3.65951800e+05, 1.42128060e+05, ...,\n",
       "        4.77106230e+05, 2.53897860e+05, 5.21142970e+05]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c955875",
   "metadata": {},
   "source": [
    "## Normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cbc9ca03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 7), dtype=float64, numpy=\n",
       "array([[5.21636963e-02, 2.37324428e-02, 1.34440221e-01, 3.32599662e-01,\n",
       "        3.63974879e-01, 5.95504312e-01, 5.28012582e-01],\n",
       "       [1.54094031e-02, 1.98260744e-01, 0.00000000e+00, 2.20134330e-03,\n",
       "        1.43420143e-01, 1.59231675e-04, 1.55770117e-04],\n",
       "       [1.87516067e-02, 0.00000000e+00, 9.34144740e-03, 0.00000000e+00,\n",
       "        1.84097952e-02, 0.00000000e+00, 1.18295981e-02],\n",
       "       [4.45817695e-01, 3.87977008e-01, 4.97659776e-01, 5.05399469e-01,\n",
       "        4.84661820e-01, 4.37597944e-01, 3.95666078e-01],\n",
       "       [2.23312309e-01, 1.80422237e-01, 2.23787475e-01, 2.57867460e-01,\n",
       "        2.04827538e-01, 2.04329329e-01, 1.93576384e-01]])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxi = tf.math.reduce_max(full_window[: , :7])\n",
    "mini = tf.math.reduce_min(full_window[: , :7])\n",
    "full_try = full_window[: , :7] / (maxi - mini)\n",
    "\n",
    "full_try[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "093c9026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_window[: , 7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19618530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 47), dtype=float64, numpy=\n",
       "array([[5.21636963e-02, 2.37324428e-02, 1.34440221e-01, 3.32599662e-01,\n",
       "        3.63974879e-01, 5.95504312e-01, 5.28012582e-01, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.54094031e-02, 1.98260744e-01, 0.00000000e+00, 2.20134330e-03,\n",
       "        1.43420143e-01, 1.59231675e-04, 1.55770117e-04, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.87516067e-02, 0.00000000e+00, 9.34144740e-03, 0.00000000e+00,\n",
       "        1.84097952e-02, 0.00000000e+00, 1.18295981e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_data = tf.concat([full_try , full_window[: , 7:]] , 1)\n",
    "combine_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "075af4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_label = full_label / (maxi - mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "270d4d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 47), dtype=float64, numpy=\n",
       " array([[0.00826229, 0.03193741, 0.01266523, 0.01678792, 0.00957366,\n",
       "         0.00464406, 0.00633839, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.35420043, 0.37005743, 0.2501399 , 0.37775669, 0.39423797,\n",
       "         0.32434376, 0.38417307, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.0833318 , 0.08277126, 0.07542541, 0.07911353, 0.09817086,\n",
       "         0.08365882, 0.09707836, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        ]])>,\n",
       " <tf.Tensor: shape=(3,), dtype=float64, numpy=array([0.00764026, 0.38069672, 0.0871766 ])>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data , test_data , train_label , test_label = train_test_split(combine_data , combine_label)\n",
    "test_data[:3] , test_label[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65917f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00356603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e8167fa",
   "metadata": {},
   "source": [
    "## Tiny Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ef4f3032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "21/21 [==============================] - 1s 13ms/step - loss: 0.0698 - val_loss: 0.0368\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0311\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0292\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0290\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0289\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0295\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0300\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0287\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0292\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0289\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0291\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0295\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0287\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0285\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0300\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0299\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0288\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0281\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0285\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0288\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0291\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0278\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0288\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0289\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0287\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0288\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0284\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0294\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0296\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0294\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0297\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0297\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0297\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0277\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 35/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0287\n",
      "Epoch 36/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0288\n",
      "Epoch 37/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0301\n",
      "Epoch 38/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0287\n",
      "Epoch 39/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0284\n",
      "Epoch 40/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0280\n",
      "Epoch 41/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0285\n",
      "Epoch 42/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0298\n",
      "Epoch 43/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0286\n",
      "Epoch 44/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0290\n",
      "Epoch 45/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0285\n",
      "Epoch 46/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0289\n",
      "Epoch 47/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0311\n",
      "Epoch 48/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0313\n",
      "Epoch 49/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0327\n",
      "Epoch 50/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0300\n",
      "Epoch 51/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0284\n",
      "Epoch 52/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0309\n",
      "Epoch 53/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0298\n",
      "Epoch 54/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0301\n",
      "Epoch 55/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0289\n",
      "Epoch 56/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0291\n",
      "Epoch 57/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0287\n",
      "Epoch 58/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0280\n",
      "Epoch 59/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0294\n",
      "Epoch 60/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0308\n",
      "Epoch 61/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0297\n",
      "Epoch 62/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0315\n",
      "Epoch 63/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0308\n",
      "Epoch 64/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0290\n",
      "Epoch 65/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0303\n",
      "Epoch 66/300\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0302\n",
      "Epoch 67/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0274\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 68/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0298\n",
      "Epoch 69/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0296\n",
      "Epoch 70/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0292\n",
      "Epoch 71/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0285\n",
      "Epoch 72/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0303\n",
      "Epoch 73/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0304\n",
      "Epoch 74/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0301\n",
      "Epoch 75/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0291\n",
      "Epoch 76/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0295\n",
      "Epoch 77/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0285\n",
      "Epoch 78/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0285\n",
      "Epoch 79/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0290\n",
      "Epoch 80/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0307\n",
      "Epoch 81/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0314\n",
      "Epoch 82/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0319\n",
      "Epoch 83/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0292\n",
      "Epoch 84/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0293\n",
      "Epoch 85/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0307\n",
      "Epoch 86/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0296\n",
      "Epoch 87/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0278\n",
      "Epoch 88/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0276\n",
      "Epoch 89/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0298\n",
      "Epoch 90/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0293\n",
      "Epoch 91/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0283\n",
      "Epoch 92/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0274\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 93/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0287\n",
      "Epoch 94/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0272\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 95/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0333\n",
      "Epoch 96/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0307\n",
      "Epoch 97/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0281\n",
      "Epoch 98/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0302\n",
      "Epoch 99/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0316\n",
      "Epoch 100/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0293\n",
      "Epoch 101/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0294\n",
      "Epoch 102/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0300\n",
      "Epoch 103/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0292\n",
      "Epoch 104/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0282\n",
      "Epoch 105/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0296\n",
      "Epoch 106/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0292\n",
      "Epoch 107/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0292\n",
      "Epoch 108/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0294\n",
      "Epoch 109/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0292\n",
      "Epoch 110/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0283\n",
      "Epoch 111/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0289\n",
      "Epoch 112/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0281\n",
      "Epoch 113/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0295\n",
      "Epoch 114/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0299\n",
      "Epoch 115/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0292\n",
      "Epoch 116/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0286\n",
      "Epoch 117/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0281\n",
      "Epoch 118/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0282\n",
      "Epoch 119/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0297\n",
      "Epoch 120/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0277\n",
      "Epoch 121/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0289\n",
      "Epoch 122/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0291\n",
      "Epoch 123/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0299\n",
      "Epoch 124/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0294\n",
      "Epoch 125/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0274\n",
      "Epoch 126/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0297\n",
      "Epoch 127/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0287\n",
      "Epoch 128/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0287\n",
      "Epoch 129/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0286\n",
      "Epoch 130/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0289\n",
      "Epoch 131/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0296\n",
      "Epoch 132/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0295\n",
      "Epoch 133/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0293\n",
      "Epoch 134/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0285\n",
      "Epoch 135/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0286\n",
      "Epoch 136/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0301\n",
      "Epoch 137/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0302\n",
      "Epoch 138/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0284\n",
      "Epoch 139/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0291\n",
      "Epoch 140/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0299\n",
      "Epoch 141/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0285\n",
      "Epoch 142/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0285\n",
      "Epoch 143/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0312\n",
      "Epoch 144/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0315\n",
      "Epoch 145/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0302\n",
      "Epoch 146/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0312\n",
      "Epoch 147/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0297\n",
      "Epoch 148/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0291\n",
      "Epoch 149/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0302\n",
      "Epoch 150/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0300\n",
      "Epoch 151/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0280\n",
      "Epoch 152/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0296\n",
      "Epoch 153/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0299\n",
      "Epoch 154/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0318\n",
      "Epoch 155/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0312\n",
      "Epoch 156/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0296\n",
      "Epoch 157/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0301\n",
      "Epoch 158/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0300\n",
      "Epoch 159/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0297\n",
      "Epoch 160/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0299\n",
      "Epoch 161/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0280\n",
      "Epoch 162/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0272\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 163/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0298\n",
      "Epoch 164/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0293\n",
      "Epoch 165/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0300\n",
      "Epoch 166/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0301\n",
      "Epoch 167/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0289\n",
      "Epoch 168/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0289\n",
      "Epoch 169/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0305\n",
      "Epoch 170/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0304\n",
      "Epoch 171/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0309\n",
      "Epoch 172/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0286\n",
      "Epoch 173/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0291\n",
      "Epoch 174/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0323\n",
      "Epoch 175/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0294\n",
      "Epoch 176/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0282\n",
      "Epoch 177/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0307\n",
      "Epoch 178/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0300\n",
      "Epoch 179/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0313\n",
      "Epoch 180/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0301\n",
      "Epoch 181/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0333\n",
      "Epoch 182/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0320\n",
      "Epoch 183/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0318\n",
      "Epoch 184/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0316\n",
      "Epoch 185/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0295\n",
      "Epoch 186/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0295\n",
      "Epoch 187/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0287\n",
      "Epoch 188/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0288\n",
      "Epoch 189/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0291\n",
      "Epoch 190/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0306\n",
      "Epoch 191/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0300\n",
      "Epoch 192/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0291\n",
      "Epoch 193/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0311\n",
      "Epoch 194/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0296\n",
      "Epoch 195/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0293\n",
      "Epoch 196/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0290\n",
      "Epoch 197/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0296\n",
      "Epoch 198/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0292\n",
      "Epoch 199/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0301\n",
      "Epoch 200/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0284\n",
      "Epoch 201/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0301\n",
      "Epoch 202/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0288\n",
      "Epoch 203/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0300\n",
      "Epoch 204/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0297\n",
      "Epoch 205/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0285\n",
      "Epoch 206/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0290\n",
      "Epoch 207/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0289\n",
      "Epoch 208/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0293\n",
      "Epoch 209/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0309\n",
      "Epoch 210/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0295\n",
      "Epoch 211/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0294\n",
      "Epoch 212/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0309\n",
      "Epoch 213/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0281\n",
      "Epoch 214/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0284\n",
      "Epoch 215/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0282\n",
      "Epoch 216/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0318\n",
      "Epoch 217/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0305\n",
      "Epoch 218/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0296\n",
      "Epoch 219/300\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0302\n",
      "Epoch 220/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0272\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 221/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0279\n",
      "Epoch 222/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0274\n",
      "Epoch 223/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0279\n",
      "Epoch 224/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0310\n",
      "Epoch 225/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0279\n",
      "Epoch 226/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0282\n",
      "Epoch 227/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0297\n",
      "Epoch 228/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0280\n",
      "Epoch 229/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0279\n",
      "Epoch 230/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0280\n",
      "Epoch 231/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0290\n",
      "Epoch 232/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0285\n",
      "Epoch 233/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0284\n",
      "Epoch 234/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0297\n",
      "Epoch 236/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0279\n",
      "Epoch 237/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0286\n",
      "Epoch 238/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0283\n",
      "Epoch 239/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0273\n",
      "Epoch 240/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0306\n",
      "Epoch 241/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0312\n",
      "Epoch 242/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0300\n",
      "Epoch 243/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0294\n",
      "Epoch 244/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0284\n",
      "Epoch 245/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0286\n",
      "Epoch 246/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0289\n",
      "Epoch 247/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0306\n",
      "Epoch 248/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0286\n",
      "Epoch 249/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0272\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Tiny_Model\\assets\n",
      "Epoch 250/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0295\n",
      "Epoch 251/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0282\n",
      "Epoch 252/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0285\n",
      "Epoch 253/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0294\n",
      "Epoch 254/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0301\n",
      "Epoch 255/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0315\n",
      "Epoch 256/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0301\n",
      "Epoch 257/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0303\n",
      "Epoch 258/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0287\n",
      "Epoch 259/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0287\n",
      "Epoch 260/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0287\n",
      "Epoch 261/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0285\n",
      "Epoch 262/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0288\n",
      "Epoch 263/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0278\n",
      "Epoch 264/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0303\n",
      "Epoch 265/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0296\n",
      "Epoch 266/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0283\n",
      "Epoch 267/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0281\n",
      "Epoch 268/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0286\n",
      "Epoch 269/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0299\n",
      "Epoch 270/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0275\n",
      "Epoch 271/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0309\n",
      "Epoch 272/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0295\n",
      "Epoch 273/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0283\n",
      "Epoch 274/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0285\n",
      "Epoch 275/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0286\n",
      "Epoch 276/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0290\n",
      "Epoch 277/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0290\n",
      "Epoch 278/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0289\n",
      "Epoch 279/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0294\n",
      "Epoch 280/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0300\n",
      "Epoch 281/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0290\n",
      "Epoch 282/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0284\n",
      "Epoch 283/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0281\n",
      "Epoch 284/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0290\n",
      "Epoch 285/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0300\n",
      "Epoch 286/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0302\n",
      "Epoch 287/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0278\n",
      "Epoch 288/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0292\n",
      "Epoch 289/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0291\n",
      "Epoch 290/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0288\n",
      "Epoch 291/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0305\n",
      "Epoch 292/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0286\n",
      "Epoch 293/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0294\n",
      "Epoch 294/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0275\n",
      "Epoch 295/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0290\n",
      "Epoch 296/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0292\n",
      "Epoch 297/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0279\n",
      "Epoch 298/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0294\n",
      "Epoch 299/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0298\n",
      "Epoch 300/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2039c9db580>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "tiny_model = tf.keras.Sequential([\n",
    "    layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) ,\n",
    "    layers.GRU(100 , activation = 'relu') , \n",
    "    layers.Dense(1 , activation = 'relu')\n",
    "] , name = 'Tiny_Model')\n",
    "\n",
    "tiny_model.compile(loss = tf.keras.losses.mae , optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "tiny_model.fit(x = train_data , y = train_label , epochs = 300 , batch_size = 128 , \n",
    "               validation_data = (test_data , test_label) , \n",
    "               callbacks=[create_model_checkpoint(model_name=tiny_model.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "606126f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 514us/step - loss: 0.0272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0271619725972414"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_model = tf.keras.models.load_model(\"model_experiments/Tiny_Model/\")\n",
    "tiny_model.evaluate(test_data , test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5c0f8373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.        , 0.3436861 , 0.09206378, 0.27256387, 0.04556163,\n",
       "       0.01453357, 0.2024903 , 0.21355343, 0.28043923, 0.1449376 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_model_preds = make_preds(tiny_model , test_data)\n",
    "tiny_model_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b3d369f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_model_preds = tf.nn.relu(tiny_model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89672758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE: ': 0.027161973, 'MSE': 0.0038540538, 'RMSE': 0.062081028, 'MAPE': 156704.77, 'Median': 0.010800427, '% error wrt median': 12.785541534423828, '% error wrt mean': 35.91157804216103, 'Min% Error': 0.0, 'Max% Error': 1089.7802734375}\n"
     ]
    }
   ],
   "source": [
    "tiny_model_error = errors(test_label , tiny_model_preds)\n",
    "print(tiny_model_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bfdd21",
   "metadata": {},
   "source": [
    "## Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd689540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "21/21 [==============================] - 1s 15ms/step - loss: 0.0609 - val_loss: 0.0351\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0296\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0284\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0296\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0282\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0288\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0293\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0283\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0292\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0282\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0294\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0282\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0280\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0296\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0294\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0313\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0276\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0286\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0306\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0301\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0281\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0320\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0277\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0295\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0301\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0287\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0313\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0294\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0272\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0285\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0297\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0307\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0304\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0307\n",
      "Epoch 35/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0291\n",
      "Epoch 36/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0279\n",
      "Epoch 37/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0281\n",
      "Epoch 38/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0287\n",
      "Epoch 39/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0282\n",
      "Epoch 40/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0281\n",
      "Epoch 41/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0296\n",
      "Epoch 42/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0325\n",
      "Epoch 43/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0292\n",
      "Epoch 44/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0300\n",
      "Epoch 45/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0312\n",
      "Epoch 46/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0282\n",
      "Epoch 47/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0279\n",
      "Epoch 48/300\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0292\n",
      "Epoch 49/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0281\n",
      "Epoch 50/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0301\n",
      "Epoch 51/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0310\n",
      "Epoch 52/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0292\n",
      "Epoch 53/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0278\n",
      "Epoch 54/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0286\n",
      "Epoch 55/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0277\n",
      "Epoch 56/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0279\n",
      "Epoch 57/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0300\n",
      "Epoch 58/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0290\n",
      "Epoch 59/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0308\n",
      "Epoch 60/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0292\n",
      "Epoch 61/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0300\n",
      "Epoch 62/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0300\n",
      "Epoch 63/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0315\n",
      "Epoch 64/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0284\n",
      "Epoch 65/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0280\n",
      "Epoch 66/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0286\n",
      "Epoch 67/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0306\n",
      "Epoch 68/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0295\n",
      "Epoch 69/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0305\n",
      "Epoch 70/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0279\n",
      "Epoch 71/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0315\n",
      "Epoch 72/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0286\n",
      "Epoch 73/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0287\n",
      "Epoch 74/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0319\n",
      "Epoch 75/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0294\n",
      "Epoch 76/300\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.016 - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0299\n",
      "Epoch 77/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0282\n",
      "Epoch 78/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0298\n",
      "Epoch 79/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0288\n",
      "Epoch 80/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0289\n",
      "Epoch 81/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0278\n",
      "Epoch 82/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0278\n",
      "Epoch 83/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0281\n",
      "Epoch 84/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0282\n",
      "Epoch 85/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0309\n",
      "Epoch 86/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0273\n",
      "Epoch 87/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0330\n",
      "Epoch 88/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0282\n",
      "Epoch 89/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0281\n",
      "Epoch 90/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0297\n",
      "Epoch 91/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0302\n",
      "Epoch 92/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0315\n",
      "Epoch 93/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0310\n",
      "Epoch 94/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0294\n",
      "Epoch 95/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0294\n",
      "Epoch 96/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0283\n",
      "Epoch 97/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0289\n",
      "Epoch 98/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0273\n",
      "Epoch 99/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0288\n",
      "Epoch 100/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0283\n",
      "Epoch 101/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0277\n",
      "Epoch 102/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0306\n",
      "Epoch 103/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0320\n",
      "Epoch 104/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0289\n",
      "Epoch 105/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0307\n",
      "Epoch 106/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0310\n",
      "Epoch 107/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0278\n",
      "Epoch 108/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0311\n",
      "Epoch 109/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0278\n",
      "Epoch 110/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0316\n",
      "Epoch 111/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0305\n",
      "Epoch 112/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0293\n",
      "Epoch 113/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0355\n",
      "Epoch 114/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0293\n",
      "Epoch 115/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0305\n",
      "Epoch 116/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0295\n",
      "Epoch 117/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0312\n",
      "Epoch 118/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0285\n",
      "Epoch 119/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0290\n",
      "Epoch 120/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0288\n",
      "Epoch 121/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0279\n",
      "Epoch 122/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0285\n",
      "Epoch 123/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0298\n",
      "Epoch 124/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0268\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Small_Model\\assets\n",
      "Epoch 125/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0295\n",
      "Epoch 126/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0282\n",
      "Epoch 127/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0296\n",
      "Epoch 128/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0288\n",
      "Epoch 129/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0274\n",
      "Epoch 130/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0307\n",
      "Epoch 131/300\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.015 - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0303\n",
      "Epoch 132/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0313\n",
      "Epoch 133/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0287\n",
      "Epoch 134/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0297\n",
      "Epoch 135/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0302\n",
      "Epoch 136/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0315\n",
      "Epoch 137/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0303\n",
      "Epoch 138/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0278\n",
      "Epoch 139/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0314\n",
      "Epoch 140/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0314\n",
      "Epoch 141/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0284\n",
      "Epoch 142/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0288\n",
      "Epoch 143/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0283\n",
      "Epoch 144/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0295\n",
      "Epoch 145/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0298\n",
      "Epoch 146/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0281\n",
      "Epoch 147/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0289\n",
      "Epoch 148/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0299\n",
      "Epoch 149/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0305\n",
      "Epoch 150/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0285\n",
      "Epoch 151/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0281\n",
      "Epoch 152/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0306\n",
      "Epoch 153/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0285\n",
      "Epoch 154/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0294\n",
      "Epoch 155/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0287\n",
      "Epoch 156/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0268\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0314\n",
      "Epoch 158/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0289\n",
      "Epoch 159/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0314\n",
      "Epoch 160/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0316\n",
      "Epoch 161/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0312\n",
      "Epoch 162/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0272\n",
      "Epoch 163/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0298\n",
      "Epoch 164/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0278\n",
      "Epoch 165/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0287\n",
      "Epoch 166/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0299\n",
      "Epoch 167/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0298\n",
      "Epoch 168/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0293\n",
      "Epoch 169/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0290\n",
      "Epoch 170/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0274\n",
      "Epoch 171/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0278\n",
      "Epoch 172/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0288\n",
      "Epoch 173/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0306\n",
      "Epoch 174/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0277\n",
      "Epoch 175/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0304\n",
      "Epoch 176/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0286\n",
      "Epoch 177/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0278\n",
      "Epoch 178/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0317\n",
      "Epoch 179/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0313\n",
      "Epoch 180/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0281\n",
      "Epoch 181/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0289\n",
      "Epoch 182/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0285\n",
      "Epoch 183/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0297\n",
      "Epoch 184/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0279\n",
      "Epoch 185/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0292\n",
      "Epoch 186/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0291\n",
      "Epoch 187/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0282\n",
      "Epoch 188/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0288\n",
      "Epoch 189/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0294\n",
      "Epoch 190/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0290\n",
      "Epoch 191/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0296\n",
      "Epoch 192/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0275\n",
      "Epoch 193/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0302\n",
      "Epoch 194/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0271\n",
      "Epoch 195/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0293\n",
      "Epoch 196/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0296\n",
      "Epoch 197/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0283\n",
      "Epoch 198/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0309\n",
      "Epoch 199/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0283\n",
      "Epoch 200/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0275\n",
      "Epoch 201/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0291\n",
      "Epoch 202/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0295\n",
      "Epoch 203/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0289\n",
      "Epoch 204/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0280\n",
      "Epoch 205/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0315\n",
      "Epoch 206/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0286\n",
      "Epoch 207/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0283\n",
      "Epoch 208/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0291\n",
      "Epoch 209/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0296\n",
      "Epoch 210/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0298\n",
      "Epoch 211/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0282\n",
      "Epoch 212/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0291\n",
      "Epoch 213/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0295\n",
      "Epoch 214/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0276\n",
      "Epoch 215/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0268\n",
      "Epoch 216/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0285\n",
      "Epoch 217/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0298\n",
      "Epoch 218/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0337\n",
      "Epoch 219/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0289\n",
      "Epoch 220/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0285\n",
      "Epoch 221/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0292\n",
      "Epoch 222/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0271\n",
      "Epoch 223/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0282\n",
      "Epoch 224/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0299\n",
      "Epoch 225/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0284\n",
      "Epoch 226/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0295\n",
      "Epoch 227/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0304\n",
      "Epoch 228/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0303\n",
      "Epoch 229/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0282\n",
      "Epoch 230/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0285\n",
      "Epoch 231/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0280\n",
      "Epoch 232/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0285\n",
      "Epoch 233/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0285\n",
      "Epoch 234/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0278\n",
      "Epoch 235/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0277\n",
      "Epoch 236/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0279\n",
      "Epoch 237/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0311\n",
      "Epoch 238/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0304\n",
      "Epoch 239/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0303\n",
      "Epoch 240/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0317\n",
      "Epoch 241/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0294\n",
      "Epoch 242/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0272\n",
      "Epoch 243/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0275\n",
      "Epoch 244/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0279\n",
      "Epoch 245/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0274\n",
      "Epoch 246/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0303\n",
      "Epoch 247/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0289\n",
      "Epoch 248/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0279\n",
      "Epoch 249/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0291\n",
      "Epoch 250/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0281\n",
      "Epoch 251/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0294\n",
      "Epoch 252/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0292\n",
      "Epoch 253/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0295\n",
      "Epoch 254/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0317\n",
      "Epoch 255/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0280\n",
      "Epoch 256/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0300\n",
      "Epoch 257/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0286\n",
      "Epoch 258/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0286\n",
      "Epoch 259/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0284\n",
      "Epoch 260/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0283\n",
      "Epoch 261/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0283\n",
      "Epoch 262/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0281\n",
      "Epoch 263/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0293\n",
      "Epoch 264/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0296\n",
      "Epoch 265/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0286\n",
      "Epoch 266/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0292\n",
      "Epoch 267/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0286\n",
      "Epoch 268/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0276\n",
      "Epoch 269/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0303\n",
      "Epoch 270/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0297\n",
      "Epoch 271/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0294\n",
      "Epoch 272/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0302\n",
      "Epoch 273/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0305\n",
      "Epoch 274/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0305\n",
      "Epoch 275/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0295\n",
      "Epoch 276/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0283\n",
      "Epoch 277/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0278\n",
      "Epoch 278/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0284\n",
      "Epoch 279/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0277\n",
      "Epoch 280/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0293\n",
      "Epoch 281/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0290\n",
      "Epoch 282/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0287\n",
      "Epoch 283/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0285\n",
      "Epoch 284/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0295\n",
      "Epoch 285/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0310\n",
      "Epoch 286/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0286\n",
      "Epoch 287/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0278\n",
      "Epoch 288/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0281\n",
      "Epoch 289/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0300\n",
      "Epoch 290/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0290\n",
      "Epoch 291/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0284\n",
      "Epoch 292/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0319\n",
      "Epoch 293/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0288\n",
      "Epoch 294/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0283\n",
      "Epoch 295/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0279\n",
      "Epoch 296/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0296\n",
      "Epoch 297/300\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0288\n",
      "Epoch 298/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0284\n",
      "Epoch 299/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0300\n",
      "Epoch 300/300\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x203b905e880>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model = tf.keras.Sequential([\n",
    "    layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) ,\n",
    "    layers.GRU(100 , activation = 'relu') , \n",
    "    layers.Dense(100 , activation = 'relu') , \n",
    "    layers.Dense(1 , activation = 'relu')\n",
    "] , name = 'Small_Model')\n",
    "\n",
    "small_model.compile(loss = tf.keras.losses.mae , optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "small_model.fit(x = train_data , y = train_label , epochs = 300 , batch_size = 128 , \n",
    "               validation_data = (test_data , test_label) , \n",
    "               callbacks=[create_model_checkpoint(model_name = small_model.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c84dc01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 851us/step - loss: 0.0268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.026753311976790428"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model = tf.keras.models.load_model(\"model_experiments/Small_Model/\")\n",
    "small_model.evaluate(test_data , test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4bfc6aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.        , 0.35321793, 0.08522871, 0.28039318, 0.04297823,\n",
       "       0.01856471, 0.21072303, 0.21429683, 0.2752472 , 0.15966758],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model_preds = make_preds(small_model , test_data)\n",
    "small_model_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b7bb1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model_preds = tf.nn.relu(small_model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "39892a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE: ': 0.026753316, 'MSE': 0.0038803536, 'RMSE': 0.062292486, 'MAPE': 284445.28, 'Median': 0.011630249, '% error wrt median': 12.981523513793945, '% error wrt mean': 33.71651765200797, 'Min% Error': 0.0, 'Max% Error': 453.2398681640625}\n"
     ]
    }
   ],
   "source": [
    "small_model_error = errors(test_label , small_model_preds)\n",
    "print(small_model_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c04632",
   "metadata": {},
   "source": [
    "## Medium Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e79ae05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "21/21 [==============================] - 2s 19ms/step - loss: 0.0497 - val_loss: 0.0374\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0257 - val_loss: 0.0294\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0234 - val_loss: 0.0284\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0222 - val_loss: 0.0288\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0214 - val_loss: 0.0278\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0212 - val_loss: 0.0279\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0216 - val_loss: 0.0316\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0212 - val_loss: 0.0331\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0212 - val_loss: 0.0327\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0215 - val_loss: 0.0286\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0216 - val_loss: 0.0275\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0211 - val_loss: 0.0311\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0211 - val_loss: 0.0271\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0214 - val_loss: 0.0275\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0200 - val_loss: 0.0291\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0207 - val_loss: 0.0262\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0288\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0202 - val_loss: 0.0271\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0204 - val_loss: 0.0281\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.0293\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0202 - val_loss: 0.0277\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0279\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0338\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0204 - val_loss: 0.0286\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0263\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0276\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.0332\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0206 - val_loss: 0.0294\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0282\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0280\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0289\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0279\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0194 - val_loss: 0.0283\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0195 - val_loss: 0.0365\n",
      "Epoch 35/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0211 - val_loss: 0.0262\n",
      "Epoch 36/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0274\n",
      "Epoch 37/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0303\n",
      "Epoch 38/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0269\n",
      "Epoch 39/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0320\n",
      "Epoch 40/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0273\n",
      "Epoch 41/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0274\n",
      "Epoch 42/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0271\n",
      "Epoch 43/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0298\n",
      "Epoch 44/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0280\n",
      "Epoch 45/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0189 - val_loss: 0.0276\n",
      "Epoch 46/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0272\n",
      "Epoch 47/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0308\n",
      "Epoch 48/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0282\n",
      "Epoch 49/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0278\n",
      "Epoch 50/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0331\n",
      "Epoch 51/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.0263\n",
      "Epoch 52/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0212 - val_loss: 0.0289\n",
      "Epoch 53/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0318\n",
      "Epoch 54/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0272\n",
      "Epoch 55/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0273\n",
      "Epoch 56/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0274\n",
      "Epoch 57/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0278\n",
      "Epoch 58/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0273\n",
      "Epoch 59/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0274\n",
      "Epoch 60/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0266\n",
      "Epoch 61/300\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.017 - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0309\n",
      "Epoch 62/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0302\n",
      "Epoch 63/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0333\n",
      "Epoch 64/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0293\n",
      "Epoch 65/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0295\n",
      "Epoch 66/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0285\n",
      "Epoch 67/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0282\n",
      "Epoch 68/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0305\n",
      "Epoch 69/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0283\n",
      "Epoch 70/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0301\n",
      "Epoch 71/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0277\n",
      "Epoch 72/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0352\n",
      "Epoch 73/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0275\n",
      "Epoch 74/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0173 - val_loss: 0.0275\n",
      "Epoch 75/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0288\n",
      "Epoch 76/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0292\n",
      "Epoch 77/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0274\n",
      "Epoch 78/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0290\n",
      "Epoch 79/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0173 - val_loss: 0.0299\n",
      "Epoch 80/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0284\n",
      "Epoch 81/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0292\n",
      "Epoch 82/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0300\n",
      "Epoch 83/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0271\n",
      "Epoch 84/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0328\n",
      "Epoch 85/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0260\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 86/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0300\n",
      "Epoch 87/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0269\n",
      "Epoch 88/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0278\n",
      "Epoch 89/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0286\n",
      "Epoch 90/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0293\n",
      "Epoch 91/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0289\n",
      "Epoch 92/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0315\n",
      "Epoch 93/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0280\n",
      "Epoch 94/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0266\n",
      "Epoch 95/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0270\n",
      "Epoch 96/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0272\n",
      "Epoch 97/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0283\n",
      "Epoch 98/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0273\n",
      "Epoch 99/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0280\n",
      "Epoch 100/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0261\n",
      "Epoch 101/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0286\n",
      "Epoch 102/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0272\n",
      "Epoch 103/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0284\n",
      "Epoch 104/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0264\n",
      "Epoch 105/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0288\n",
      "Epoch 106/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0270\n",
      "Epoch 107/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0295\n",
      "Epoch 108/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0266\n",
      "Epoch 109/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0304\n",
      "Epoch 110/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0286\n",
      "Epoch 111/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0279\n",
      "Epoch 112/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0260\n",
      "Epoch 113/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0269\n",
      "Epoch 114/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0282\n",
      "Epoch 115/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0291\n",
      "Epoch 116/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0278\n",
      "Epoch 117/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0302\n",
      "Epoch 118/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0285\n",
      "Epoch 119/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0279\n",
      "Epoch 120/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0274\n",
      "Epoch 121/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0289\n",
      "Epoch 122/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0323\n",
      "Epoch 123/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0277\n",
      "Epoch 124/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0277\n",
      "Epoch 125/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0271\n",
      "Epoch 126/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0159 - val_loss: 0.0291\n",
      "Epoch 127/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0286\n",
      "Epoch 128/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0273\n",
      "Epoch 129/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0277\n",
      "Epoch 130/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0287\n",
      "Epoch 131/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0267\n",
      "Epoch 132/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0282\n",
      "Epoch 133/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0273\n",
      "Epoch 134/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0270\n",
      "Epoch 135/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0272\n",
      "Epoch 136/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0286\n",
      "Epoch 137/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0267\n",
      "Epoch 138/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0297\n",
      "Epoch 139/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0287\n",
      "Epoch 140/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0266\n",
      "Epoch 141/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0317\n",
      "Epoch 142/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0279\n",
      "Epoch 143/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0285\n",
      "Epoch 144/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0295\n",
      "Epoch 145/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0303\n",
      "Epoch 146/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0275\n",
      "Epoch 147/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0272\n",
      "Epoch 148/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0278\n",
      "Epoch 149/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0276\n",
      "Epoch 150/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0316\n",
      "Epoch 151/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0273\n",
      "Epoch 152/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0263\n",
      "Epoch 153/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0155 - val_loss: 0.0282\n",
      "Epoch 154/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0308\n",
      "Epoch 155/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0262\n",
      "Epoch 156/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0310\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0296\n",
      "Epoch 158/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0293\n",
      "Epoch 159/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0277\n",
      "Epoch 160/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0282\n",
      "Epoch 161/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0289\n",
      "Epoch 162/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0273\n",
      "Epoch 163/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0300\n",
      "Epoch 164/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0282\n",
      "Epoch 165/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0294\n",
      "Epoch 166/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0284\n",
      "Epoch 167/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0294\n",
      "Epoch 168/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0266\n",
      "Epoch 169/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0286\n",
      "Epoch 170/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0269\n",
      "Epoch 171/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0308\n",
      "Epoch 172/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0280\n",
      "Epoch 173/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0303\n",
      "Epoch 174/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0293\n",
      "Epoch 175/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0264\n",
      "Epoch 176/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0288\n",
      "Epoch 177/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0268\n",
      "Epoch 178/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0264\n",
      "Epoch 179/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0281\n",
      "Epoch 180/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0289\n",
      "Epoch 181/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0269\n",
      "Epoch 182/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0283\n",
      "Epoch 183/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0283\n",
      "Epoch 184/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0287\n",
      "Epoch 185/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0282\n",
      "Epoch 186/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0299\n",
      "Epoch 187/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0149 - val_loss: 0.0278\n",
      "Epoch 188/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0267\n",
      "Epoch 189/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0329\n",
      "Epoch 190/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0276\n",
      "Epoch 191/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0324\n",
      "Epoch 192/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0151 - val_loss: 0.0300\n",
      "Epoch 193/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0277\n",
      "Epoch 194/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0281\n",
      "Epoch 195/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0266\n",
      "Epoch 196/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0282\n",
      "Epoch 197/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0312\n",
      "Epoch 198/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0256\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 199/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0285\n",
      "Epoch 200/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0294\n",
      "Epoch 201/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0288\n",
      "Epoch 202/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0300\n",
      "Epoch 203/300\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0141 - val_loss: 0.0270\n",
      "Epoch 204/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0287\n",
      "Epoch 205/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0267\n",
      "Epoch 206/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0266\n",
      "Epoch 207/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0264\n",
      "Epoch 208/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0302\n",
      "Epoch 209/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0293\n",
      "Epoch 210/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0281\n",
      "Epoch 211/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0254\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Medium_Model\\assets\n",
      "Epoch 212/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0277\n",
      "Epoch 213/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0266\n",
      "Epoch 214/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0289\n",
      "Epoch 215/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0315\n",
      "Epoch 216/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0300\n",
      "Epoch 217/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0260\n",
      "Epoch 218/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0272\n",
      "Epoch 219/300\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0290\n",
      "Epoch 220/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0272\n",
      "Epoch 221/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0297\n",
      "Epoch 222/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0286\n",
      "Epoch 223/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0272\n",
      "Epoch 224/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0289\n",
      "Epoch 225/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0263\n",
      "Epoch 226/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0294\n",
      "Epoch 227/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0281\n",
      "Epoch 228/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0313\n",
      "Epoch 229/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0278\n",
      "Epoch 230/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0282\n",
      "Epoch 231/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0265\n",
      "Epoch 232/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0294\n",
      "Epoch 233/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0294\n",
      "Epoch 234/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0287\n",
      "Epoch 235/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0300\n",
      "Epoch 236/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0282\n",
      "Epoch 238/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0268\n",
      "Epoch 239/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0302\n",
      "Epoch 240/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0269\n",
      "Epoch 241/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0274\n",
      "Epoch 242/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0281\n",
      "Epoch 243/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0327\n",
      "Epoch 244/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0269\n",
      "Epoch 245/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0263\n",
      "Epoch 246/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0287\n",
      "Epoch 247/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0283\n",
      "Epoch 248/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0291\n",
      "Epoch 249/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0266\n",
      "Epoch 250/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0304\n",
      "Epoch 251/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0285\n",
      "Epoch 252/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0270\n",
      "Epoch 253/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0282\n",
      "Epoch 254/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0293\n",
      "Epoch 255/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0268\n",
      "Epoch 256/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0290\n",
      "Epoch 257/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0280\n",
      "Epoch 258/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0273\n",
      "Epoch 259/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0139 - val_loss: 0.0302\n",
      "Epoch 260/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0274\n",
      "Epoch 261/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0296\n",
      "Epoch 262/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0267\n",
      "Epoch 263/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0271\n",
      "Epoch 264/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0282\n",
      "Epoch 265/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0274\n",
      "Epoch 266/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0292\n",
      "Epoch 267/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0290\n",
      "Epoch 268/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0275\n",
      "Epoch 269/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0306\n",
      "Epoch 270/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0263\n",
      "Epoch 271/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0264\n",
      "Epoch 272/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0285\n",
      "Epoch 273/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0284\n",
      "Epoch 274/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0293\n",
      "Epoch 275/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0277\n",
      "Epoch 276/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0279\n",
      "Epoch 277/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0287\n",
      "Epoch 278/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0286\n",
      "Epoch 279/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0290\n",
      "Epoch 280/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0285\n",
      "Epoch 281/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0306\n",
      "Epoch 282/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0272\n",
      "Epoch 283/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0306\n",
      "Epoch 284/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0283\n",
      "Epoch 285/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0302\n",
      "Epoch 286/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0281\n",
      "Epoch 287/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0295\n",
      "Epoch 288/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0282\n",
      "Epoch 289/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0276\n",
      "Epoch 290/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0271\n",
      "Epoch 291/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0270\n",
      "Epoch 292/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0296\n",
      "Epoch 293/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0279\n",
      "Epoch 294/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0311\n",
      "Epoch 295/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0268\n",
      "Epoch 296/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0292\n",
      "Epoch 297/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0288\n",
      "Epoch 298/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0296\n",
      "Epoch 299/300\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0272\n",
      "Epoch 300/300\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x203ab3e4f70>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_model = tf.keras.Sequential([\n",
    "    layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) ,\n",
    "    layers.GRU(300 , activation = 'relu') , \n",
    "    layers.Dense(300 , activation = 'relu') , \n",
    "    layers.Dense(300 , activation = 'relu') , \n",
    "    layers.Dense(1 , activation = 'relu')\n",
    "] , name = 'Medium_Model')\n",
    "\n",
    "medium_model.compile(loss = tf.keras.losses.mae , optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "medium_model.fit(x = train_data , y = train_label , epochs = 300 , batch_size = 128 , \n",
    "               validation_data = (test_data , test_label) , \n",
    "               callbacks=[create_model_checkpoint(model_name = medium_model.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "db91c47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02542370930314064"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_model = tf.keras.models.load_model(\"model_experiments/Medium_Model/\")\n",
    "medium_model.evaluate(test_data , test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "391327bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.00800249, 0.35307908, 0.08953201, 0.2892795 , 0.0435142 ,\n",
       "       0.01659892, 0.21504202, 0.20584637, 0.27860004, 0.15738466],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_model_preds = make_preds(medium_model , test_data)\n",
    "medium_model_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5aceb678",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_model_preds = tf.nn.relu(medium_model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ab198315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE: ': 0.025423711, 'MSE': 0.0038542124, 'RMSE': 0.0620823, 'MAPE': 328252.72, 'Median': 0.008705486, '% error wrt median': 10.866072654724121, '% error wrt mean': 43.859119025358396, 'Min% Error': 0.0, 'Max% Error': 5776.53662109375}\n"
     ]
    }
   ],
   "source": [
    "medium_model_error = errors(test_label , medium_model_preds)\n",
    "print(medium_model_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeb377c",
   "metadata": {},
   "source": [
    "## Large Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e3e22321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "21/21 [==============================] - 2s 36ms/step - loss: 0.0465 - val_loss: 0.0296\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0242 - val_loss: 0.0299\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0224 - val_loss: 0.0295\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0228 - val_loss: 0.0404\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0219 - val_loss: 0.0283\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0212 - val_loss: 0.0278\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0209 - val_loss: 0.0275\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0214 - val_loss: 0.0320\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0213 - val_loss: 0.0269\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0212 - val_loss: 0.0298\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0226 - val_loss: 0.0302\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0211 - val_loss: 0.0300\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0207 - val_loss: 0.0286\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0213 - val_loss: 0.0331\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0207 - val_loss: 0.0284\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0217 - val_loss: 0.0262\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0213 - val_loss: 0.0322\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0207 - val_loss: 0.0294\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0201 - val_loss: 0.0276\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0199 - val_loss: 0.0265\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0201 - val_loss: 0.0276\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0203 - val_loss: 0.0300\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0206 - val_loss: 0.0288\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0204 - val_loss: 0.0298\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0212 - val_loss: 0.0347\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0202 - val_loss: 0.0307\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0200 - val_loss: 0.0261\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0200 - val_loss: 0.0286\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0195 - val_loss: 0.0351\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0227 - val_loss: 0.0292\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0197 - val_loss: 0.0291\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0192 - val_loss: 0.0282\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 0.0194 - val_loss: 0.0286\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0194 - val_loss: 0.0297\n",
      "Epoch 35/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0192 - val_loss: 0.0283\n",
      "Epoch 36/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0201 - val_loss: 0.0284\n",
      "Epoch 37/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0210 - val_loss: 0.0343\n",
      "Epoch 38/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0199 - val_loss: 0.0347\n",
      "Epoch 39/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0209 - val_loss: 0.0352\n",
      "Epoch 40/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0215 - val_loss: 0.0272\n",
      "Epoch 41/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0197 - val_loss: 0.0271\n",
      "Epoch 42/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0200 - val_loss: 0.0274\n",
      "Epoch 43/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0198 - val_loss: 0.0264\n",
      "Epoch 44/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0198 - val_loss: 0.0306\n",
      "Epoch 45/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0190 - val_loss: 0.0303\n",
      "Epoch 46/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0195 - val_loss: 0.0294\n",
      "Epoch 47/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0189 - val_loss: 0.0314\n",
      "Epoch 48/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0189 - val_loss: 0.0278\n",
      "Epoch 49/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0187 - val_loss: 0.0264\n",
      "Epoch 50/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0193 - val_loss: 0.0262\n",
      "Epoch 51/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0190 - val_loss: 0.0257\n",
      "INFO:tensorflow:Assets written to: model_experiments\\Large_Model\\assets\n",
      "Epoch 52/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0206 - val_loss: 0.0317\n",
      "Epoch 53/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0196 - val_loss: 0.0279\n",
      "Epoch 54/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0185 - val_loss: 0.0321\n",
      "Epoch 55/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0185 - val_loss: 0.0269\n",
      "Epoch 56/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0188 - val_loss: 0.0272\n",
      "Epoch 57/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0189 - val_loss: 0.0266\n",
      "Epoch 58/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0203 - val_loss: 0.0312\n",
      "Epoch 59/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0186 - val_loss: 0.0329\n",
      "Epoch 60/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0179 - val_loss: 0.0310\n",
      "Epoch 61/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0192 - val_loss: 0.0281\n",
      "Epoch 62/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0188 - val_loss: 0.0271\n",
      "Epoch 63/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0291\n",
      "Epoch 64/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0179 - val_loss: 0.0264\n",
      "Epoch 65/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0185 - val_loss: 0.0271\n",
      "Epoch 66/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0178 - val_loss: 0.0264\n",
      "Epoch 67/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0185 - val_loss: 0.0305\n",
      "Epoch 68/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0182 - val_loss: 0.0362\n",
      "Epoch 69/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0186 - val_loss: 0.0305\n",
      "Epoch 70/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0184 - val_loss: 0.0283\n",
      "Epoch 71/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0186 - val_loss: 0.0289\n",
      "Epoch 72/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0180 - val_loss: 0.0274\n",
      "Epoch 73/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0177 - val_loss: 0.0268\n",
      "Epoch 74/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0175 - val_loss: 0.0275\n",
      "Epoch 75/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0178 - val_loss: 0.0289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0193 - val_loss: 0.0316\n",
      "Epoch 77/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0176 - val_loss: 0.0279\n",
      "Epoch 78/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0287\n",
      "Epoch 79/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0176 - val_loss: 0.0292\n",
      "Epoch 80/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0177 - val_loss: 0.0346\n",
      "Epoch 81/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0185 - val_loss: 0.0305\n",
      "Epoch 82/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0177 - val_loss: 0.0265\n",
      "Epoch 83/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0179 - val_loss: 0.0272\n",
      "Epoch 84/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0177 - val_loss: 0.0301\n",
      "Epoch 85/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0299\n",
      "Epoch 86/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0289\n",
      "Epoch 87/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0277\n",
      "Epoch 88/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0172 - val_loss: 0.0278\n",
      "Epoch 89/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0176 - val_loss: 0.0377\n",
      "Epoch 90/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0186 - val_loss: 0.0294\n",
      "Epoch 91/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0169 - val_loss: 0.0348\n",
      "Epoch 92/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0178 - val_loss: 0.0272\n",
      "Epoch 93/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0172 - val_loss: 0.0274\n",
      "Epoch 94/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0171 - val_loss: 0.0308\n",
      "Epoch 95/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0342\n",
      "Epoch 96/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0174 - val_loss: 0.0279\n",
      "Epoch 97/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0170 - val_loss: 0.0308\n",
      "Epoch 98/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0169 - val_loss: 0.0292\n",
      "Epoch 99/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0168 - val_loss: 0.0282\n",
      "Epoch 100/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0298\n",
      "Epoch 101/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0289\n",
      "Epoch 102/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0168 - val_loss: 0.0287\n",
      "Epoch 103/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0168 - val_loss: 0.0329\n",
      "Epoch 104/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0181 - val_loss: 0.0276\n",
      "Epoch 105/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0170 - val_loss: 0.0285\n",
      "Epoch 106/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0168 - val_loss: 0.0377\n",
      "Epoch 107/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0189 - val_loss: 0.0266\n",
      "Epoch 108/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0176 - val_loss: 0.0295\n",
      "Epoch 109/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0170 - val_loss: 0.0323\n",
      "Epoch 110/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0308\n",
      "Epoch 111/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0173 - val_loss: 0.0280\n",
      "Epoch 112/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0170 - val_loss: 0.0316\n",
      "Epoch 113/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0166 - val_loss: 0.0309\n",
      "Epoch 114/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0163 - val_loss: 0.0296\n",
      "Epoch 115/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0163 - val_loss: 0.0312\n",
      "Epoch 116/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0165 - val_loss: 0.0312\n",
      "Epoch 117/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0163 - val_loss: 0.0281\n",
      "Epoch 118/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0163 - val_loss: 0.0292\n",
      "Epoch 119/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0163 - val_loss: 0.0283\n",
      "Epoch 120/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0174 - val_loss: 0.0344\n",
      "Epoch 121/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0164 - val_loss: 0.0297\n",
      "Epoch 122/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0164 - val_loss: 0.0287\n",
      "Epoch 123/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0160 - val_loss: 0.0298\n",
      "Epoch 124/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0167 - val_loss: 0.0293\n",
      "Epoch 125/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0159 - val_loss: 0.0289\n",
      "Epoch 126/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0163 - val_loss: 0.0324\n",
      "Epoch 127/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0169 - val_loss: 0.0279\n",
      "Epoch 128/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0281\n",
      "Epoch 129/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0170 - val_loss: 0.0292\n",
      "Epoch 130/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0168 - val_loss: 0.0290\n",
      "Epoch 131/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0164 - val_loss: 0.0305\n",
      "Epoch 132/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0165 - val_loss: 0.0281\n",
      "Epoch 133/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0159 - val_loss: 0.0284\n",
      "Epoch 134/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0156 - val_loss: 0.0296\n",
      "Epoch 135/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0277\n",
      "Epoch 136/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0166 - val_loss: 0.0284\n",
      "Epoch 137/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0159 - val_loss: 0.0284\n",
      "Epoch 138/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0308\n",
      "Epoch 139/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0174 - val_loss: 0.0273\n",
      "Epoch 140/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0165 - val_loss: 0.0331\n",
      "Epoch 141/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0170 - val_loss: 0.0293\n",
      "Epoch 142/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0172 - val_loss: 0.0321\n",
      "Epoch 143/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0314\n",
      "Epoch 144/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0160 - val_loss: 0.0301\n",
      "Epoch 145/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0273\n",
      "Epoch 146/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0156 - val_loss: 0.0328\n",
      "Epoch 147/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0289\n",
      "Epoch 148/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0287\n",
      "Epoch 149/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0294\n",
      "Epoch 150/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0159 - val_loss: 0.0269\n",
      "Epoch 151/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0320\n",
      "Epoch 152/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0270\n",
      "Epoch 153/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0162 - val_loss: 0.0309\n",
      "Epoch 154/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0291\n",
      "Epoch 155/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0153 - val_loss: 0.0297\n",
      "Epoch 156/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0161 - val_loss: 0.0272\n",
      "Epoch 157/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0290\n",
      "Epoch 158/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0156 - val_loss: 0.0310\n",
      "Epoch 159/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0153 - val_loss: 0.0281\n",
      "Epoch 160/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0152 - val_loss: 0.0289\n",
      "Epoch 161/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0154 - val_loss: 0.0301\n",
      "Epoch 162/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0304\n",
      "Epoch 163/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0282\n",
      "Epoch 164/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0157 - val_loss: 0.0330\n",
      "Epoch 165/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0276\n",
      "Epoch 166/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0153 - val_loss: 0.0307\n",
      "Epoch 167/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0152 - val_loss: 0.0278\n",
      "Epoch 168/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0306\n",
      "Epoch 169/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0156 - val_loss: 0.0277\n",
      "Epoch 170/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0158 - val_loss: 0.0269\n",
      "Epoch 171/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0150 - val_loss: 0.0295\n",
      "Epoch 172/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0158 - val_loss: 0.0272\n",
      "Epoch 173/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0163 - val_loss: 0.0299\n",
      "Epoch 174/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0148 - val_loss: 0.0280\n",
      "Epoch 175/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0305\n",
      "Epoch 176/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0151 - val_loss: 0.0302\n",
      "Epoch 177/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0152 - val_loss: 0.0291\n",
      "Epoch 178/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0153 - val_loss: 0.0271\n",
      "Epoch 179/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0154 - val_loss: 0.0321\n",
      "Epoch 180/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0281\n",
      "Epoch 181/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0148 - val_loss: 0.0293\n",
      "Epoch 182/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0158 - val_loss: 0.0265\n",
      "Epoch 183/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0154 - val_loss: 0.0313\n",
      "Epoch 184/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0283\n",
      "Epoch 185/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0149 - val_loss: 0.0279\n",
      "Epoch 186/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0165 - val_loss: 0.0360\n",
      "Epoch 187/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0174 - val_loss: 0.0347\n",
      "Epoch 188/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0161 - val_loss: 0.0310\n",
      "Epoch 189/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0157 - val_loss: 0.0298\n",
      "Epoch 190/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0156 - val_loss: 0.0277\n",
      "Epoch 191/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0273\n",
      "Epoch 192/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0149 - val_loss: 0.0289\n",
      "Epoch 193/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0332\n",
      "Epoch 194/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0305\n",
      "Epoch 195/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0287\n",
      "Epoch 196/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0144 - val_loss: 0.0284\n",
      "Epoch 197/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0147 - val_loss: 0.0280\n",
      "Epoch 198/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0294\n",
      "Epoch 199/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0301\n",
      "Epoch 200/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0267\n",
      "Epoch 201/300\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0155 - val_loss: 0.0336\n",
      "Epoch 202/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0159 - val_loss: 0.0272\n",
      "Epoch 203/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0148 - val_loss: 0.0294\n",
      "Epoch 204/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0145 - val_loss: 0.0287\n",
      "Epoch 205/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0318\n",
      "Epoch 206/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0273\n",
      "Epoch 207/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0298\n",
      "Epoch 208/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0340\n",
      "Epoch 209/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0151 - val_loss: 0.0263\n",
      "Epoch 210/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0286\n",
      "Epoch 211/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0142 - val_loss: 0.0287\n",
      "Epoch 212/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0142 - val_loss: 0.0287\n",
      "Epoch 213/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0145 - val_loss: 0.0317\n",
      "Epoch 214/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0145 - val_loss: 0.0277\n",
      "Epoch 215/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0154 - val_loss: 0.0300\n",
      "Epoch 216/300\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0147 - val_loss: 0.0304\n",
      "Epoch 217/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0142 - val_loss: 0.0313\n",
      "Epoch 218/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0147 - val_loss: 0.0305\n",
      "Epoch 219/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0277\n",
      "Epoch 220/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0146 - val_loss: 0.0268\n",
      "Epoch 221/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0142 - val_loss: 0.0266\n",
      "Epoch 222/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0142 - val_loss: 0.0303\n",
      "Epoch 223/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0275\n",
      "Epoch 224/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0142 - val_loss: 0.0315\n",
      "Epoch 225/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0147 - val_loss: 0.0280\n",
      "Epoch 226/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0143 - val_loss: 0.0272\n",
      "Epoch 227/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0146 - val_loss: 0.0287\n",
      "Epoch 228/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0142 - val_loss: 0.0298\n",
      "Epoch 229/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0298\n",
      "Epoch 230/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0277\n",
      "Epoch 231/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0137 - val_loss: 0.0302\n",
      "Epoch 232/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0140 - val_loss: 0.0298\n",
      "Epoch 233/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0302\n",
      "Epoch 234/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0145 - val_loss: 0.0283\n",
      "Epoch 235/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0141 - val_loss: 0.0287\n",
      "Epoch 236/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0137 - val_loss: 0.0289\n",
      "Epoch 237/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0139 - val_loss: 0.0297\n",
      "Epoch 238/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0142 - val_loss: 0.0274\n",
      "Epoch 239/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0140 - val_loss: 0.0346\n",
      "Epoch 240/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0322\n",
      "Epoch 241/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0154 - val_loss: 0.0267\n",
      "Epoch 242/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0145 - val_loss: 0.0294\n",
      "Epoch 243/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0144 - val_loss: 0.0263\n",
      "Epoch 244/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0144 - val_loss: 0.0281\n",
      "Epoch 245/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0137 - val_loss: 0.0285\n",
      "Epoch 246/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0138 - val_loss: 0.0293\n",
      "Epoch 247/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0284\n",
      "Epoch 248/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0136 - val_loss: 0.0280\n",
      "Epoch 249/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0294\n",
      "Epoch 250/300\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0135 - val_loss: 0.0269\n",
      "Epoch 251/300\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0144 - val_loss: 0.0297\n",
      "Epoch 252/300\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0142 - val_loss: 0.0285\n",
      "Epoch 253/300\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0139 - val_loss: 0.0282\n",
      "Epoch 254/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0139 - val_loss: 0.0301\n",
      "Epoch 255/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0310\n",
      "Epoch 256/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0146 - val_loss: 0.0270\n",
      "Epoch 257/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0137 - val_loss: 0.0273\n",
      "Epoch 258/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0152 - val_loss: 0.0295\n",
      "Epoch 259/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0139 - val_loss: 0.0276\n",
      "Epoch 260/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0293\n",
      "Epoch 261/300\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0135 - val_loss: 0.0306\n",
      "Epoch 262/300\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0133 - val_loss: 0.0263\n",
      "Epoch 263/300\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0139 - val_loss: 0.0309\n",
      "Epoch 264/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0143 - val_loss: 0.0264\n",
      "Epoch 265/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0298\n",
      "Epoch 266/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0136 - val_loss: 0.0288\n",
      "Epoch 267/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0138 - val_loss: 0.0292\n",
      "Epoch 268/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0273\n",
      "Epoch 269/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0135 - val_loss: 0.0305\n",
      "Epoch 270/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0281\n",
      "Epoch 271/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0134 - val_loss: 0.0281\n",
      "Epoch 272/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0137 - val_loss: 0.0305\n",
      "Epoch 273/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0137 - val_loss: 0.0275\n",
      "Epoch 274/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0138 - val_loss: 0.0291\n",
      "Epoch 275/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0304\n",
      "Epoch 276/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0142 - val_loss: 0.0325\n",
      "Epoch 277/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0135 - val_loss: 0.0270\n",
      "Epoch 278/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0135 - val_loss: 0.0283\n",
      "Epoch 279/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0134 - val_loss: 0.0297\n",
      "Epoch 280/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0139 - val_loss: 0.0284\n",
      "Epoch 281/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0144 - val_loss: 0.0314\n",
      "Epoch 282/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0288\n",
      "Epoch 283/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0137 - val_loss: 0.0278\n",
      "Epoch 284/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0132 - val_loss: 0.0282\n",
      "Epoch 285/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0134 - val_loss: 0.0280\n",
      "Epoch 286/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0131 - val_loss: 0.0315\n",
      "Epoch 287/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0136 - val_loss: 0.0285\n",
      "Epoch 288/300\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.0133 - val_loss: 0.0284\n",
      "Epoch 289/300\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0131 - val_loss: 0.0267\n",
      "Epoch 290/300\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0132 - val_loss: 0.0263\n",
      "Epoch 291/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0137 - val_loss: 0.0292\n",
      "Epoch 292/300\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0133 - val_loss: 0.0293\n",
      "Epoch 293/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0135 - val_loss: 0.0282\n",
      "Epoch 294/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0129 - val_loss: 0.0286\n",
      "Epoch 295/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0132 - val_loss: 0.0282\n",
      "Epoch 296/300\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0131 - val_loss: 0.0280\n",
      "Epoch 297/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0137 - val_loss: 0.0312\n",
      "Epoch 298/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0150 - val_loss: 0.0261\n",
      "Epoch 299/300\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0139 - val_loss: 0.0290\n",
      "Epoch 300/300\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0135 - val_loss: 0.0273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x203c5a67580>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_model = tf.keras.Sequential([\n",
    "    layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) ,\n",
    "    layers.GRU(512 , activation = 'relu') , \n",
    "    layers.Lambda(lambda x: tf.expand_dims(x, axis=1)) ,\n",
    "    layers.Dense(512 , activation = 'relu') , \n",
    "    layers.Dense(512 , activation = 'relu') ,\n",
    "    layers.Dense(512 , activation = 'relu') ,\n",
    "    layers.Dense(1 , activation = 'relu')\n",
    "] , name = 'Large_Model')\n",
    "\n",
    "large_model.compile(loss = tf.keras.losses.mae , optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "large_model.fit(x = train_data , y = train_label , epochs = 300 , batch_size = 128 , \n",
    "               validation_data = (test_data , test_label) , \n",
    "               callbacks=[create_model_checkpoint(model_name = large_model.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8470fcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02573590911924839"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_model = tf.keras.models.load_model(\"model_experiments/Large_Model/\")\n",
    "large_model.evaluate(test_data , test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee4e1a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.0071335 , 0.3590504 , 0.09298075, 0.3005424 , 0.03535212,\n",
       "       0.01569966, 0.22187753, 0.24166933, 0.29623926, 0.16588236],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_model_preds = make_preds(large_model , test_data)\n",
    "large_model_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b60b88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_model_preds = tf.nn.relu(large_model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e2c8c53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE: ': 0.025735911, 'MSE': 0.0038146512, 'RMSE': 0.061762862, 'MAPE': 314445.25, 'Median': 0.009154161, '% error wrt median': 12.58082914352417, '% error wrt mean': 29.056579712664686, 'Min% Error': 0.0, 'Max% Error': 1043.606201171875}\n"
     ]
    }
   ],
   "source": [
    "large_model_error = errors(test_label , large_model_preds)\n",
    "print(large_model_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1d313cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "combined_model_preds = (medium_model_preds + tiny_model_preds + large_model_preds + small_model_preds) / 4\n",
    "upper , lower = upper_lower(test_label , combined_model_preds)\n",
    "dictionary = {'True Value' : test_label , 'Prediction' : medium_model_preds , 'Upper' : upper , 'Lower' : lower}\n",
    "datas = pd.DataFrame(dictionary)\n",
    "\n",
    "for i in range(len(datas)):\n",
    "    if(datas.iloc[i].loc['Upper'] < datas.iloc[i].loc['True Value']):\n",
    "        datas.loc[i , 'Outlier'] = 1\n",
    "    \n",
    "    elif(datas.iloc[i].loc['Lower'] > datas.iloc[i].loc['True Value']):\n",
    "        datas.loc[i , 'Outlier'] = -1\n",
    "\n",
    "up = datas.where(datas['Outlier'] > 0)\n",
    "up.dropna(subset = [\"Outlier\"] , inplace=True)\n",
    "print(len(up))\n",
    "\n",
    "down = datas.where(datas['Outlier'] < 0)\n",
    "down.dropna(subset = [\"Outlier\"], inplace=True)\n",
    "print(len(down))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
